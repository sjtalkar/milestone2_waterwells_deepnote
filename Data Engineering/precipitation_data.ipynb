{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Precipitation data gathering and creation of precipitation dataset",
   "metadata": {
    "cell_id": "4500339f-1db4-4ecd-b8e3-4f7fd1ae4e2d",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 82
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a6d58109-9b68-420b-b922-48542d672a64",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7cddc2e6",
    "execution_start": 1647453789731,
    "execution_millis": 1,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 369
   },
   "source": "import pandas as pd\nimport numpy as np\n\nfrom bs4 import BeautifulSoup\nimport requests\n\nimport datetime\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\nimport json\nimport geopandas as gpd\nimport pygeos\n\nimport altair as alt",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "##### NOTE: The outputof this notebook after scraped data was cleaned and merged is stored in \n **\"/work/milestone2_waterwells_deepnote/assets/inputs/precipitation/precipitation_stations.csv\"**",
   "metadata": {
    "cell_id": "00001-94e2870a-75ee-46c0-97df-5afc3f8d7f8c",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 88.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "### SECTION 1 Scrape Precipitation data from daily reporting stations\n- Web scraping with BeautifulSoup4 \n- The trick is to understanding the HTML structure to rerieve the rows of data\n- Data is retieved from the daily reporting site\n-  We scrape the data at weekly level",
   "metadata": {
    "cell_id": "00002-e0ae0e92-e4a5-4aa9-9f29-4d627e8faea2",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 190.59375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00003-30451161-36b8-4a66-ae2b-47dec6f4c3ff",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5ccef0e2",
    "execution_start": 1647453988625,
    "execution_millis": 7,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 963
   },
   "source": "def scrape_monthly_precipitation_data(year_start, year_end):\n    \"\"\"\n        This function loops through a set of years in a list\n        It creates URLS at yearly level for precipitation In each URL, the data is at monthly level\n        It creates one dataframe containing precipitation data at monthly level for years for which we have data\n    \"\"\"\n    \n    all_years_precipitation_data = pd.DataFrame()\n    for curr_year in range(year_start,year_end + 1):\n    \n        url=f\"https://cdec.water.ca.gov/reportapp/javareports?name=PRECIPMON.{curr_year}\"\n\n        # Make a GET request to fetch the raw HTML content\n        html_content = requests.get(url).text\n\n        # Parse the html content\n        soup = BeautifulSoup(html_content, \"lxml\")\n\n        precipitation_table = soup.find(\"table\", attrs={\"id\":\"data\", \"class\": \"data\"})\n      \n        if precipitation_table is None:\n                continue\n        \n        precipitation_table_header = precipitation_table.thead.find_all(\"th\")  \n        precipitation_table_header = [th.text for th in precipitation_table_header]\n        precipitation_table_header = precipitation_table_header[1:]\n        precipitation_table_rows = precipitation_table.find_all('tr')\n        all_rows_list = []\n        for eachTableRow in precipitation_table_rows:\n            this_row = []\n            for td in eachTableRow.find_all(\"td\"):\n                this_row.append(td.text.strip())\n\n            if this_row and len(this_row) > 1:\n                all_rows_list.append(this_row)\n\n        data_table = pd.DataFrame(all_rows_list )\n        data_table.columns = precipitation_table_header\n        for col in ['OCT', 'NOV', 'DEC', 'JAN', 'FEB', 'MAR','APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP']:\n            data_table[col] = pd.to_numeric(data_table[col], errors='coerce')\n        data_table['AVERAGE_YEARLY_PRECIPITATION'] =  data_table[ ['OCT', 'NOV', 'DEC', 'JAN', 'FEB', 'MAR','APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP']].mean(axis='columns')\n        data_table['YEAR'] = curr_year\n        data_table.rename(columns = {'STATION ID':'STATION_ID'}, inplace=True)\n      \n        if all_years_precipitation_data.empty:\n                all_years_precipitation_data = data_table \n        else:\n                all_years_precipitation_data  = all_years_precipitation_data.append(data_table)\n    return all_years_precipitation_data\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Get Monthly Precipitation Reporting Station locations using webscraping",
   "metadata": {
    "cell_id": "00006-00fc94cf-9f2f-4777-a779-002a88386481",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00007-71934d06-e942-4609-9c45-be981f7bcdb6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8f81ac97",
    "execution_start": 1647454323896,
    "execution_millis": 1,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 675
   },
   "source": "def get_precipitation_station_data(level):\n    \n    if level == 'daily':\n        url=f\"https://cdec.water.ca.gov/reportapp/javareports?name=DailyStations\"\n    else:\n        url=  \"https://cdec.water.ca.gov/reportapp/javareports?name=MonthlyPrecip\"\n\n\n    # Make a GET request to fetch the raw HTML content\n    html_content = requests.get(url).text\n\n    # Parse the html content\n    soup = BeautifulSoup(html_content, \"lxml\")\n\n    if level == 'daily':\n            station_table = soup.find(\"table\", attrs={\"id\":\"DLY_STNLIST\", \"class\": \"data\"})\n    else:\n            station_table = soup.find(\"table\", attrs={\"id\":\"REALPRECIP_LIST\", \"class\": \"data\"})\n\n    all_rows_list = []\n    for eachRow in station_table.find_all(\"tr\"):\n        this_row = []\n        for  td in eachRow.find_all(\"td\"):\n            this_row.append(td.text.strip())\n\n        if this_row and len(this_row) > 1:\n             all_rows_list.append(this_row)\n    station_table = pd.DataFrame(all_rows_list )\n    station_table.columns = station_table.iloc[0,:]\n    station_table =  station_table.iloc[2:,:].copy()\n    station_table.rename(columns={'ID':'STATION_ID'}, inplace=True)\n    station_table.drop(columns=['ELEV(FEET)'], inplace = True)\n    return station_table\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00008-f2b3e0bd-4357-48cf-aed5-ed5e851e3990",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6a9d452e",
    "execution_start": 1647454491547,
    "execution_millis": 1,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 351
   },
   "source": "def retrieve_merge_precipitation_stations(): \n    all_years_precipitation_data = scrape_monthly_precipitation_data(2013, 2022) #1767\n\n\n    daily_station_table = get_precipitation_station_data('daily')\n    monthly_station_table = get_precipitation_station_data('monthly')\n\n    full_station_table = daily_station_table.append(monthly_station_table)\n    group_full_station_count_df = full_station_table.groupby(['STATION', 'STATION_ID','LATITUDE', 'LONGITUDE', 'COUNTY' ]).agg(count_latitude=('LATITUDE', 'count')).reset_index()\n    #Making sure we do not have duplicates\n    #group_full_station_count_df[group_full_station_count_df.station_id.str.contains('ASM|ATW|BFK|BAL|YSV')]\n    group_full_station_count_df.drop(columns=['count_latitude'], inplace=True)\n\n    all_years_precipitation_station = all_years_precipitation_data.merge(group_full_station_count_df, how='inner', left_on='STATION_ID', right_on='STATION_ID')\n    all_years_precipitation_station.drop(columns=[ 'STATION'], inplace=True)\n    return all_years_precipitation_station",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00009-ddb2e893-378c-47a7-b32d-86cf0ed4cfb0",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 138
   },
   "source": "#list(set(all_years_precipitation_data.station_id) - set(monthly_station_table.station_id))\n#list(set(all_years_precipitation_data.station_id) - set(full_station_table.station_id))\n# There are stations not found on the site either ['MTP', 'CHL', 'LSB', 'HRR', 'GNV', 'LGB', 'LYT']\n# all_years_precipitation_station = all_years_precipitation_data.merge(monthly_station_table, how='left', left_on='STATION_ID', right_on='STATION_ID', indicator=True)\n# all_years_precipitation_station[all_years_precipitation_station['_merge']  != 'both'].station_id.unique()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "#all_years_precipitation_station.describe()",
   "metadata": {
    "cell_id": "f8b7fa58-a052-42a5-be3e-a19436f10fdc",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "86d189b",
    "execution_start": 1647455518083,
    "execution_millis": 2,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81,
    "deepnote_output_heights": [
     611
    ]
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00010-51849a11-cea0-461d-8253-e48d8987ecae",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "80d59a56",
    "execution_start": 1647455529817,
    "execution_millis": 26,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "def save_precipitation_data(all_years_precipitation_station):\n    all_years_precipitation_station.to_csv(r\"/work/milestone2_waterwells_deepnote/assets/inputs/precipitation/precipitation_stations.csv\", index=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00011-77111b7c-9deb-4f3d-9ca1-a154ae02030a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cbaa8445",
    "execution_start": 1647455532364,
    "execution_millis": 75,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "save_precipitation_data(all_years_precipitation_station)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00012-2a89950a-cddc-4af2-a8ff-ac36ef69f9de",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 66
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b042e2da-6536-449d-95b8-d85fa08825de' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "deepnote_notebook_id": "24a8cb1f-14c4-4e46-8e52-6385c9b447a7",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}