{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "cell_id": "b08e59fa-1fa9-45b5-80dc-20bc41aeac6f",
    "deepnote_cell_type": "code"
   },
   "source": "import sys\nsys.path.append('..')",
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00001-9d4c544d-9134-45bb-a3e3-82d0e4b5bc1a",
    "deepnote_cell_type": "code"
   },
   "source": "import numpy as np\nimport pandas as pd\nimport pickle\n\nimport neptune.new as neptune\nfrom neptune.new.integrations.tensorflow_keras import NeptuneCallback\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nimport tensorflow\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\nfrom keras.optimizers import RMSprop, Adam, Adamax\n\nfrom lib.read_data import read_and_join_output_file\n#from lib.create_pipeline import create_transformation_pipeline\nfrom lib.deeplearning import create_transformation_pipelines\nfrom lib.transform_impute import convert_back_df\nfrom lib.split_data import train_test_group_time_split",
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00002-37fa7ed4-076a-46b0-aea3-e7d3169e3543",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Num GPUs Available:  0\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00003-38d12750-8465-41a5-b235-d88f4e6e34d0",
    "deepnote_cell_type": "code"
   },
   "source": "# During experiment we can try to use neptune.ai to log all the Tensorflow experiments results\nneptune_key = pickle.load(open(\"./neptune.pkl\", \"rb\"))\n",
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Preparing the Dataset\nThe train and test sets are split by Township-Ranges, i.e. some Township-Ranges data are either fully in the train or test set.\nThe target value is the value of that variable for 2021\nThus train/test sets are of shape (number of Township-Ranges, 7 years (2014-2020), the number of features).\nThe input of 1 data point in the model is of shape (7x81\n",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "cell_id": "00004-fff4b4fd-b061-41fb-ad29-7cbf57fcfd66",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00005-14ca660a-7d29-49d7-b40d-3bc1dfe4648c",
    "deepnote_cell_type": "code"
   },
   "source": "RANDOM_SEED = 42\n# Load the data from the ETL output files\nX = read_and_join_output_file()\n#X[\"WELL_COUNT\"] = X[\"WELL_COUNT_PUBLIC\"] + X[\"WELL_COUNT_AGRICULTURE\"] + X[\"WELL_COUNT_DOMESTIC\"] + X[\"WELL_COUNT_INDUSTRIAL\"]\n#X.drop(columns=[\"WELL_COUNT_PUBLIC\", \"WELL_COUNT_AGRICULTURE\", \"WELL_COUNT_DOMESTIC\", \"WELL_COUNT_INDUSTRIAL\"], inplace=True)\n# Split the data into a training and a test set\nX_train_df, X_test_df, y_train_df, y_test_df = train_test_group_time_split(X, index=[\"TOWNSHIP_RANGE\", \"YEAR\"], group=\"TOWNSHIP_RANGE\", random_seed=RANDOM_SEED)\n# Create, fit and apply the data imputation pipeline to the training and test sets\nimpute_pipeline, columns = create_transformation_pipelines(X_train_df)\nX_train_impute = impute_pipeline.fit_transform(X_train_df)\nX_test_impute = impute_pipeline.transform(X_test_df)\n# Convert the X_train and X_test back to dataframes\nX_train_impute_df = pd.DataFrame(X_train_impute, index=X_train_df.index, columns=columns)\nX_test_impute_df = pd.DataFrame(X_test_impute, index=X_test_df.index, columns=columns)\n# Keep only the GSE_GWE variable as the outcome variable\nscaler = MinMaxScaler()\ny_train = scaler.fit_transform(y_train_df[[\"GSE_GWE\"]])\ny_test = scaler.transform(y_test_df[[\"GSE_GWE\"]])\nX_train_impute_df",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "                     TOTALDRILLDEPTH_AVG  WELLYIELD_AVG  STATICWATERLEVEL_AVG  \\\nTOWNSHIP_RANGE YEAR                                                             \nT01N R03E      2014             0.097778       0.018246              0.037145   \n               2015             0.095238       0.021053              0.025042   \n               2016             0.114286       0.007916              0.022398   \n               2017             0.000000       0.013684              0.030885   \n               2018             0.083873       0.002474              0.034558   \n...                                  ...            ...                   ...   \nT32S R30E      2016             0.000000       0.000000              0.000000   \n               2017             0.000000       0.000000              0.000000   \n               2018             0.000000       0.000000              0.000000   \n               2019             0.000000       0.000000              0.000000   \n               2020             0.000000       0.000000              0.000000   \n\n                     TOPOFPERFORATEDINTERVAL_AVG  \\\nTOWNSHIP_RANGE YEAR                                \nT01N R03E      2014                     0.098039   \n               2015                     0.117647   \n               2016                     0.152614   \n               2017                     0.127451   \n               2018                     0.148257   \n...                                          ...   \nT32S R30E      2016                     0.000000   \n               2017                     0.000000   \n               2018                     0.000000   \n               2019                     0.000000   \n               2020                     0.000000   \n\n                     BOTTOMOFPERFORATEDINTERVAL_AVG  TOTALCOMPLETEDDEPTH_AVG  \\\nTOWNSHIP_RANGE YEAR                                                            \nT01N R03E      2014                        0.111111                 0.105856   \n               2015                        0.080460                 0.079848   \n               2016                        0.103768                 0.104880   \n               2017                        0.082375                 0.081749   \n               2018                        0.093934                 0.107605   \n...                                             ...                      ...   \nT32S R30E      2016                        0.000000                 0.000000   \n               2017                        0.000000                 0.000000   \n               2018                        0.000000                 0.000000   \n               2019                        0.000000                 0.000000   \n               2020                        0.000000                 0.000000   \n\n                     VEGETATION_BLUE_OAK-GRAY_PINE  \\\nTOWNSHIP_RANGE YEAR                                  \nT01N R03E      2014                       0.000037   \n               2015                       0.000037   \n               2016                       0.000037   \n               2017                       0.000037   \n               2018                       0.000037   \n...                                            ...   \nT32S R30E      2016                       0.033178   \n               2017                       0.033178   \n               2018                       0.033178   \n               2019                       0.033178   \n               2020                       0.033178   \n\n                     VEGETATION_CALIFORNIA_COAST_LIVE_OAK  \\\nTOWNSHIP_RANGE YEAR                                         \nT01N R03E      2014                              0.000137   \n               2015                              0.000137   \n               2016                              0.000137   \n               2017                              0.000137   \n               2018                              0.000137   \n...                                                   ...   \nT32S R30E      2016                              0.000000   \n               2017                              0.000000   \n               2018                              0.000000   \n               2019                              0.000000   \n               2020                              0.000000   \n\n                     VEGETATION_CANYON_LIVE_OAK  VEGETATION_HARD_CHAPARRAL  \\\nTOWNSHIP_RANGE YEAR                                                          \nT01N R03E      2014                    0.000000                   0.000386   \n               2015                    0.000000                   0.000386   \n               2016                    0.000000                   0.000386   \n               2017                    0.000000                   0.000386   \n               2018                    0.000000                   0.000386   \n...                                         ...                        ...   \nT32S R30E      2016                    0.002023                   0.003535   \n               2017                    0.002023                   0.003535   \n               2018                    0.002023                   0.003535   \n               2019                    0.002023                   0.003535   \n               2020                    0.002023                   0.003535   \n\n                     ...  POPULATION_DENSITY  PCT_OF_CAPACITY  \\\nTOWNSHIP_RANGE YEAR  ...                                        \nT01N R03E      2014  ...            0.252900         0.717075   \n               2015  ...            0.252799         0.717075   \n               2016  ...            0.250621         0.717075   \n               2017  ...            0.254669         0.717075   \n               2018  ...            0.256461         0.800728   \n...                  ...                 ...              ...   \nT32S R30E      2016  ...            0.004469         0.496289   \n               2017  ...            0.004457         0.496289   \n               2018  ...            0.004474         0.496289   \n               2019  ...            0.004491         0.580893   \n               2020  ...            0.004512         0.499980   \n\n                     GROUNDSURFACEELEVATION_AVG  AVERAGE_YEARLY_PRECIPITATION  \\\nTOWNSHIP_RANGE YEAR                                                             \nT01N R03E      2014                    0.023626                      0.163573   \n               2015                    0.018249                      0.217900   \n               2016                    0.024153                      0.209056   \n               2017                    0.023541                      0.213645   \n               2018                    0.020523                      0.181012   \n...                                         ...                           ...   \nT32S R30E      2016                    0.139007                      0.111564   \n               2017                    0.139007                      0.169284   \n               2018                    0.139007                      0.079747   \n               2019                    0.139007                      0.158678   \n               2020                    0.139007                      0.156231   \n\n                     SHORTAGE_COUNT   GSE_GWE  WELL_COUNT_AGRICULTURE  \\\nTOWNSHIP_RANGE YEAR                                                     \nT01N R03E      2014             0.0  0.043005                0.029412   \n               2015             0.0  0.050637                0.000000   \n               2016             0.0  0.035780                0.029412   \n               2017             0.0  0.033202                0.000000   \n               2018             0.0  0.030798                0.000000   \n...                             ...       ...                     ...   \nT32S R30E      2016             0.0  0.621728                0.000000   \n               2017             0.0  0.527907                0.000000   \n               2018             0.0  0.556283                0.000000   \n               2019             0.0  0.566892                0.000000   \n               2020             0.0  0.555112                0.000000   \n\n                     WELL_COUNT_DOMESTIC  WELL_COUNT_INDUSTRIAL  \\\nTOWNSHIP_RANGE YEAR                                               \nT01N R03E      2014             0.041667                    0.0   \n               2015             0.027778                    0.0   \n               2016             0.055556                    0.0   \n               2017             0.027778                    0.0   \n               2018             0.097222                    0.0   \n...                                  ...                    ...   \nT32S R30E      2016             0.000000                    0.0   \n               2017             0.000000                    0.0   \n               2018             0.000000                    0.0   \n               2019             0.000000                    0.0   \n               2020             0.000000                    0.0   \n\n                     WELL_COUNT_PUBLIC  \nTOWNSHIP_RANGE YEAR                     \nT01N R03E      2014                0.0  \n               2015                0.0  \n               2016                0.0  \n               2017                0.0  \n               2018                0.0  \n...                                ...  \nT32S R30E      2016                0.0  \n               2017                0.0  \n               2018                0.0  \n               2019                0.0  \n               2020                0.0  \n\n[2674 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>TOTALDRILLDEPTH_AVG</th>\n      <th>WELLYIELD_AVG</th>\n      <th>STATICWATERLEVEL_AVG</th>\n      <th>TOPOFPERFORATEDINTERVAL_AVG</th>\n      <th>BOTTOMOFPERFORATEDINTERVAL_AVG</th>\n      <th>TOTALCOMPLETEDDEPTH_AVG</th>\n      <th>VEGETATION_BLUE_OAK-GRAY_PINE</th>\n      <th>VEGETATION_CALIFORNIA_COAST_LIVE_OAK</th>\n      <th>VEGETATION_CANYON_LIVE_OAK</th>\n      <th>VEGETATION_HARD_CHAPARRAL</th>\n      <th>...</th>\n      <th>POPULATION_DENSITY</th>\n      <th>PCT_OF_CAPACITY</th>\n      <th>GROUNDSURFACEELEVATION_AVG</th>\n      <th>AVERAGE_YEARLY_PRECIPITATION</th>\n      <th>SHORTAGE_COUNT</th>\n      <th>GSE_GWE</th>\n      <th>WELL_COUNT_AGRICULTURE</th>\n      <th>WELL_COUNT_DOMESTIC</th>\n      <th>WELL_COUNT_INDUSTRIAL</th>\n      <th>WELL_COUNT_PUBLIC</th>\n    </tr>\n    <tr>\n      <th>TOWNSHIP_RANGE</th>\n      <th>YEAR</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">T01N R03E</th>\n      <th>2014</th>\n      <td>0.097778</td>\n      <td>0.018246</td>\n      <td>0.037145</td>\n      <td>0.098039</td>\n      <td>0.111111</td>\n      <td>0.105856</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.252900</td>\n      <td>0.717075</td>\n      <td>0.023626</td>\n      <td>0.163573</td>\n      <td>0.0</td>\n      <td>0.043005</td>\n      <td>0.029412</td>\n      <td>0.041667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>0.095238</td>\n      <td>0.021053</td>\n      <td>0.025042</td>\n      <td>0.117647</td>\n      <td>0.080460</td>\n      <td>0.079848</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.252799</td>\n      <td>0.717075</td>\n      <td>0.018249</td>\n      <td>0.217900</td>\n      <td>0.0</td>\n      <td>0.050637</td>\n      <td>0.000000</td>\n      <td>0.027778</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2016</th>\n      <td>0.114286</td>\n      <td>0.007916</td>\n      <td>0.022398</td>\n      <td>0.152614</td>\n      <td>0.103768</td>\n      <td>0.104880</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.250621</td>\n      <td>0.717075</td>\n      <td>0.024153</td>\n      <td>0.209056</td>\n      <td>0.0</td>\n      <td>0.035780</td>\n      <td>0.029412</td>\n      <td>0.055556</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>0.000000</td>\n      <td>0.013684</td>\n      <td>0.030885</td>\n      <td>0.127451</td>\n      <td>0.082375</td>\n      <td>0.081749</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.254669</td>\n      <td>0.717075</td>\n      <td>0.023541</td>\n      <td>0.213645</td>\n      <td>0.0</td>\n      <td>0.033202</td>\n      <td>0.000000</td>\n      <td>0.027778</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.083873</td>\n      <td>0.002474</td>\n      <td>0.034558</td>\n      <td>0.148257</td>\n      <td>0.093934</td>\n      <td>0.107605</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.256461</td>\n      <td>0.800728</td>\n      <td>0.020523</td>\n      <td>0.181012</td>\n      <td>0.0</td>\n      <td>0.030798</td>\n      <td>0.000000</td>\n      <td>0.097222</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">T32S R30E</th>\n      <th>2016</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004469</td>\n      <td>0.496289</td>\n      <td>0.139007</td>\n      <td>0.111564</td>\n      <td>0.0</td>\n      <td>0.621728</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004457</td>\n      <td>0.496289</td>\n      <td>0.139007</td>\n      <td>0.169284</td>\n      <td>0.0</td>\n      <td>0.527907</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004474</td>\n      <td>0.496289</td>\n      <td>0.139007</td>\n      <td>0.079747</td>\n      <td>0.0</td>\n      <td>0.556283</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2019</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004491</td>\n      <td>0.580893</td>\n      <td>0.139007</td>\n      <td>0.158678</td>\n      <td>0.0</td>\n      <td>0.566892</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004512</td>\n      <td>0.499980</td>\n      <td>0.139007</td>\n      <td>0.156231</td>\n      <td>0.0</td>\n      <td>0.555112</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2674 rows × 81 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00006-332d228f-2141-4ffd-960d-99da5ea178e6",
    "deepnote_cell_type": "code"
   },
   "source": "# Change the shape of the input array to (number of Township-Ranges, 7 years (2014-2020), the number of features)\nX_train = X_train_impute_df.values.reshape(len(X_train_impute_df.index.get_level_values(0).unique()), len(X_train_impute_df.index.get_level_values(1).unique()), X_train_impute_df.shape[1])\nX_test = X_test_impute_df.values.reshape(len(X_test_impute_df.index.get_level_values(0).unique()), len(X_test_impute_df.index.get_level_values(1).unique()), X_test_impute_df.shape[1])",
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00007-c376ddc6-3ecc-4ce5-a601-1bbb0502437a",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"=\"*100)\nprint(\"Checking the train, validation and test input (X) datasets sizes:\")\nprint(f\"Size of the X_train dataset: {X_train.shape}\")\n#print(f\"Size of the X_val dataset: {X_val.shape}\")\nprint(f\"Size of the X_test dataset: {X_test.shape}\")\nprint(\"=\"*100)\nprint(\"Checking the train, validation and test output (y) datasets sizes:\")\nprint(f\"Size of the y_train dataset: {y_train.shape}\")\n#print(f\"Size of the y_val dataset: {y_val_df.shape}\")\nprint(f\"Size of the y_test dataset: {y_test.shape}\")",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "====================================================================================================\nChecking the train, validation and test input (X) datasets sizes:\nSize of the X_train dataset: (382, 7, 81)\nSize of the X_test dataset: (96, 7, 81)\n====================================================================================================\nChecking the train, validation and test output (y) datasets sizes:\nSize of the y_train dataset: (382, 1)\nSize of the y_test dataset: (96, 1)\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00008-06f5bdb6-889b-4720-bcf8-2bbbde94f3e6",
    "deepnote_cell_type": "code"
   },
   "source": "results_df = y_test_df[[\"GSE_GWE\"]].copy()",
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00009-214f6386-c27c-4bd4-8ed9-74da64719dae",
    "deepnote_cell_type": "code"
   },
   "source": "nb_features = len(X_train_impute_df.columns)\n\nhyper_parameters = {\n    \"validation_split\": 0.05,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n    \"epochs\": 30,\n    \"lstm_units\": 200,\n    \"lstm_activation\": \"tanh\",\n    \"output_activation\": \"linear\",\n    \"nb_features\": nb_features,\n    \"optimizer\": \"RMSprop\"\n}\n\noptimizer = {\n    \"RMSprop\": RMSprop(learning_rate=hyper_parameters[\"learning_rate\"]),\n    \"Adam\": Adam(learning_rate=hyper_parameters[\"learning_rate\"]),\n    \"Adamax\": Adamax(learning_rate=hyper_parameters[\"learning_rate\"])\n}",
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00010-ac1e85eb-2cd0-4cf4-90d2-2ab19ea9238d",
    "deepnote_cell_type": "code"
   },
   "source": "def evaluate_forecast(y_test_inverse, yhat_inverse):\n    mse_ = keras.metrics.MeanSquaredError()\n    mae_ = keras.metrics.MeanAbsoluteError()\n    rmse_ = keras.metrics.RootMeanSquaredError()\n    mae = mae_(y_test_inverse,yhat_inverse)\n    print('mae:', mae)\n    mse = mse_(y_test_inverse,yhat_inverse)\n    print('mse:', mse)\n    rmse = rmse_(y_test_inverse,yhat_inverse)\n    print('rmse:', rmse)\n    return mae, mse, rmse",
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00011-40d90f1b-e40a-4a4e-a7aa-330e1caa4ecf",
    "deepnote_cell_type": "code"
   },
   "source": "model1 = Sequential()\nmodel1.add(LSTM(hyper_parameters[\"lstm_units\"], activation=hyper_parameters[\"lstm_activation\"], input_shape=(7, nb_features)))\nmodel1.add(Dense(1, activation=hyper_parameters[\"output_activation\"]))\nmodel1.summary()",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm_8 (LSTM)               (None, 200)               225600    \n                                                                 \n dense_12 (Dense)            (None, 1)                 201       \n                                                                 \n=================================================================\nTotal params: 225,801\nTrainable params: 225,801\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00012-caf9dda4-7490-4cc1-942b-ad5a4997e5c8",
    "deepnote_cell_type": "code"
   },
   "source": "# Start experiment\nrun = neptune.init(\n    project=\"milestone2-california-water-shortage/deeplearning-lstm\",\n    api_token=neptune_key,\n    name=\"Basic Model\",\n    tags=[\"WithDetailedWellCounts\", \"UnidirectionalLSTM\"]\n)\nneptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')\nrun['hyper-parameters'] = hyper_parameters\n\nmodel1.compile(loss=\"mse\", optimizer=optimizer[hyper_parameters[\"optimizer\"]])\nhistory = model1.fit(X_train, y_train,\n                     validation_split=hyper_parameters[\"validation_split\"],\n                     batch_size=hyper_parameters[\"batch_size\"],\n                     epochs=hyper_parameters[\"epochs\"],\n                     shuffle=True,\n                     callbacks=[neptune_cbk])\nyhat = model1.predict(X_test, verbose=0)\nyhat_inverse = scaler.inverse_transform(yhat)\ny_test_inverse = scaler.inverse_transform(y_test)\nresults_df[\"experiment_1_prediction\"] = yhat_inverse\nmae, mse, rmse = evaluate_forecast(y_test_inverse, yhat_inverse)\nrun[\"eval/mae\"] = mae\nrun[\"eval/mse\"] = mse\nrun[\"eval/rmse\"] = rmse\nrun.stop()",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-50\nRemember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\nEpoch 1/30\n12/12 [==============================] - 3s 133ms/step - loss: 0.0301 - val_loss: 0.0097\nEpoch 2/30\n12/12 [==============================] - 1s 102ms/step - loss: 0.0092 - val_loss: 0.0066\nEpoch 3/30\n12/12 [==============================] - 1s 73ms/step - loss: 0.0077 - val_loss: 0.0134\nEpoch 4/30\n12/12 [==============================] - 1s 60ms/step - loss: 0.0056 - val_loss: 0.0093\nEpoch 5/30\n12/12 [==============================] - 1s 57ms/step - loss: 0.0049 - val_loss: 0.0198\nEpoch 6/30\n12/12 [==============================] - 1s 61ms/step - loss: 0.0065 - val_loss: 0.0068\nEpoch 7/30\n12/12 [==============================] - 1s 58ms/step - loss: 0.0041 - val_loss: 0.0042\nEpoch 8/30\n12/12 [==============================] - 1s 59ms/step - loss: 0.0044 - val_loss: 0.0074\nEpoch 9/30\n12/12 [==============================] - 1s 57ms/step - loss: 0.0042 - val_loss: 0.0171\nEpoch 10/30\n12/12 [==============================] - 1s 62ms/step - loss: 0.0042 - val_loss: 0.0085\nEpoch 11/30\n12/12 [==============================] - 1s 60ms/step - loss: 0.0036 - val_loss: 0.0040\nEpoch 12/30\n12/12 [==============================] - 1s 71ms/step - loss: 0.0042 - val_loss: 0.0086\nEpoch 13/30\n12/12 [==============================] - 1s 90ms/step - loss: 0.0036 - val_loss: 0.0048\nEpoch 14/30\n12/12 [==============================] - 1s 90ms/step - loss: 0.0034 - val_loss: 0.0138\nEpoch 15/30\n12/12 [==============================] - 1s 96ms/step - loss: 0.0029 - val_loss: 0.0047\nEpoch 16/30\n12/12 [==============================] - 1s 78ms/step - loss: 0.0032 - val_loss: 0.0132\nEpoch 17/30\n12/12 [==============================] - 1s 55ms/step - loss: 0.0028 - val_loss: 0.0078\nEpoch 18/30\n12/12 [==============================] - 1s 63ms/step - loss: 0.0030 - val_loss: 0.0075\nEpoch 19/30\n12/12 [==============================] - 1s 61ms/step - loss: 0.0032 - val_loss: 0.0071\nEpoch 20/30\n12/12 [==============================] - 1s 61ms/step - loss: 0.0027 - val_loss: 0.0027\nEpoch 21/30\n12/12 [==============================] - 1s 67ms/step - loss: 0.0024 - val_loss: 0.0043\nEpoch 22/30\n12/12 [==============================] - 1s 56ms/step - loss: 0.0023 - val_loss: 0.0034\nEpoch 23/30\n12/12 [==============================] - 1s 84ms/step - loss: 0.0032 - val_loss: 0.0053\nEpoch 24/30\n12/12 [==============================] - 1s 113ms/step - loss: 0.0020 - val_loss: 0.0030\nEpoch 25/30\n12/12 [==============================] - 1s 110ms/step - loss: 0.0020 - val_loss: 0.0095\nEpoch 26/30\n12/12 [==============================] - 1s 101ms/step - loss: 0.0025 - val_loss: 0.0033\nEpoch 27/30\n12/12 [==============================] - 1s 63ms/step - loss: 0.0025 - val_loss: 0.0023\nEpoch 28/30\n12/12 [==============================] - 1s 59ms/step - loss: 0.0022 - val_loss: 0.0029\nEpoch 29/30\n12/12 [==============================] - 1s 62ms/step - loss: 0.0023 - val_loss: 0.0022\nEpoch 30/30\n12/12 [==============================] - 1s 58ms/step - loss: 0.0024 - val_loss: 0.0025\nmae: tf.Tensor(37.12118, shape=(), dtype=float32)\nmse: tf.Tensor(3138.0247, shape=(), dtype=float32)\nrmse: tf.Tensor(56.018074, shape=(), dtype=float32)\nShutting down background jobs, please wait a moment...\nDone!\nWaiting for the remaining 91 operations to synchronize with Neptune. Do not kill this process.\nAll 91 operations synced, thanks for waiting!\nExplore the metadata in the Neptune app:\nhttps://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-50\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00013-d51c444b-1b3d-4ecf-a953-7294556d8c30",
    "deepnote_cell_type": "code"
   },
   "source": "hyper_parameters[\"dense_units\"] = 30\nhyper_parameters[\"dense_activation\"] = \"tanh\"\nhyper_parameters[\"dropout\"] = 0.02\n\nmodel2 = Sequential()\nmodel2.add(Bidirectional(LSTM(hyper_parameters[\"lstm_units\"], activation=hyper_parameters[\"lstm_activation\"]), input_shape=(7, nb_features)))\nmodel2.add(Dense(hyper_parameters[\"dense_units\"], activation=hyper_parameters[\"dense_activation\"]))\nmodel2.add(Dropout(hyper_parameters[\"dropout\"]))\nmodel2.add(Dense(1, activation=hyper_parameters[\"output_activation\"]))\nmodel2.summary()",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_9\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bidirectional_4 (Bidirectio  (None, 400)              451200    \n nal)                                                            \n                                                                 \n dense_13 (Dense)            (None, 30)                12030     \n                                                                 \n dropout_4 (Dropout)         (None, 30)                0         \n                                                                 \n dense_14 (Dense)            (None, 1)                 31        \n                                                                 \n=================================================================\nTotal params: 463,261\nTrainable params: 463,261\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00014-f50e4cd9-e2f1-4617-85d2-3f6dbd20d0e3",
    "deepnote_cell_type": "code"
   },
   "source": "run = neptune.init(\n    project=\"milestone2-california-water-shortage/deeplearning-lstm\",\n    api_token=neptune_key,\n    name=\"Advanced Model 1\",\n    tags=[\"WithDetailedWellCounts\", \"BidirectionalLSTM\"]\n)\nneptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')\nrun['hyper-parameters'] = hyper_parameters\n\nmodel2.compile(loss=\"mse\", optimizer=optimizer[hyper_parameters[\"optimizer\"]])\nhistory = model2.fit(X_train, y_train,\n                     validation_split=hyper_parameters[\"validation_split\"],\n                     batch_size=hyper_parameters[\"batch_size\"],\n                     epochs=hyper_parameters[\"epochs\"],\n                     shuffle=True,\n                     callbacks=[neptune_cbk])\nyhat = model2.predict(X_test, verbose=0)\nyhat_inverse = scaler.inverse_transform(yhat)\ny_test_inverse = scaler.inverse_transform(y_test)\nresults_df[\"experiment_2_prediction\"] = yhat_inverse\nevaluate_forecast(y_test_inverse, yhat_inverse)\nmae, mse, rmse = evaluate_forecast(y_test_inverse, yhat_inverse)\nrun[\"eval/mae\"] = mae\nrun[\"eval/mse\"] = mse\nrun[\"eval/rmse\"] = rmse\nrun.stop()",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-51\nRemember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\nEpoch 1/30\n12/12 [==============================] - 6s 272ms/step - loss: 0.0746 - val_loss: 0.0081\nEpoch 2/30\n12/12 [==============================] - 2s 151ms/step - loss: 0.0089 - val_loss: 0.0044\nEpoch 3/30\n12/12 [==============================] - 2s 153ms/step - loss: 0.0114 - val_loss: 0.0089\nEpoch 4/30\n12/12 [==============================] - 2s 164ms/step - loss: 0.0111 - val_loss: 0.0079\nEpoch 5/30\n12/12 [==============================] - 3s 273ms/step - loss: 0.0121 - val_loss: 0.0059\nEpoch 6/30\n12/12 [==============================] - 2s 188ms/step - loss: 0.0060 - val_loss: 0.0083\nEpoch 7/30\n12/12 [==============================] - 2s 153ms/step - loss: 0.0081 - val_loss: 0.0062\nEpoch 8/30\n12/12 [==============================] - 2s 156ms/step - loss: 0.0051 - val_loss: 0.0064\nEpoch 9/30\n12/12 [==============================] - 3s 217ms/step - loss: 0.0066 - val_loss: 0.0064\nEpoch 10/30\n12/12 [==============================] - 3s 275ms/step - loss: 0.0049 - val_loss: 0.0227\nEpoch 11/30\n12/12 [==============================] - 2s 153ms/step - loss: 0.0072 - val_loss: 0.0069\nEpoch 12/30\n12/12 [==============================] - 2s 157ms/step - loss: 0.0042 - val_loss: 0.0118\nEpoch 13/30\n12/12 [==============================] - 3s 218ms/step - loss: 0.0050 - val_loss: 0.0081\nEpoch 14/30\n12/12 [==============================] - 3s 278ms/step - loss: 0.0062 - val_loss: 0.0057\nEpoch 15/30\n12/12 [==============================] - 2s 176ms/step - loss: 0.0056 - val_loss: 0.0171\nEpoch 16/30\n12/12 [==============================] - 2s 166ms/step - loss: 0.0040 - val_loss: 0.0088\nEpoch 17/30\n12/12 [==============================] - 2s 167ms/step - loss: 0.0051 - val_loss: 0.0070\nEpoch 18/30\n12/12 [==============================] - 3s 241ms/step - loss: 0.0037 - val_loss: 0.0122\nEpoch 19/30\n12/12 [==============================] - 3s 231ms/step - loss: 0.0032 - val_loss: 0.0068\nEpoch 20/30\n12/12 [==============================] - 2s 161ms/step - loss: 0.0045 - val_loss: 0.0037\nEpoch 21/30\n12/12 [==============================] - 2s 162ms/step - loss: 0.0035 - val_loss: 0.0055\nEpoch 22/30\n12/12 [==============================] - 3s 230ms/step - loss: 0.0035 - val_loss: 0.0072\nEpoch 23/30\n12/12 [==============================] - 3s 264ms/step - loss: 0.0036 - val_loss: 0.0174\nEpoch 24/30\n12/12 [==============================] - 2s 157ms/step - loss: 0.0033 - val_loss: 0.0113\nEpoch 25/30\n12/12 [==============================] - 2s 156ms/step - loss: 0.0042 - val_loss: 0.0132\nEpoch 26/30\n12/12 [==============================] - 2s 178ms/step - loss: 0.0035 - val_loss: 0.0167\nEpoch 27/30\n12/12 [==============================] - 3s 259ms/step - loss: 0.0025 - val_loss: 0.0063\nEpoch 28/30\n12/12 [==============================] - 3s 210ms/step - loss: 0.0030 - val_loss: 0.0061\nEpoch 29/30\n12/12 [==============================] - 2s 154ms/step - loss: 0.0035 - val_loss: 0.0066\nEpoch 30/30\n12/12 [==============================] - 2s 160ms/step - loss: 0.0030 - val_loss: 0.0108\nmae: tf.Tensor(50.12213, shape=(), dtype=float32)\nmse: tf.Tensor(4345.498, shape=(), dtype=float32)\nrmse: tf.Tensor(65.920395, shape=(), dtype=float32)\nmae: tf.Tensor(50.12213, shape=(), dtype=float32)\nmse: tf.Tensor(4345.498, shape=(), dtype=float32)\nrmse: tf.Tensor(65.920395, shape=(), dtype=float32)\nShutting down background jobs, please wait a moment...\nDone!\nWaiting for the remaining 80 operations to synchronize with Neptune. Do not kill this process.\nAll 80 operations synced, thanks for waiting!\nExplore the metadata in the Neptune app:\nhttps://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-51\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00015-71f17e9f-49e9-491a-ad21-4c4630e24015",
    "deepnote_cell_type": "code"
   },
   "source": "results_df",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "                        GSE_GWE  experiment_1_prediction  \\\nTOWNSHIP_RANGE YEAR                                        \nT01N R02E      2021   53.193636                36.336391   \nT01N R11E      2021  107.955000               142.946442   \nT01S R03E      2021   24.494538                18.849447   \nT01S R07E      2021   38.644000                23.731907   \nT01S R10E      2021  113.651250               104.674149   \n...                         ...                      ...   \nT31S R26E      2021  173.915909               179.801483   \nT31S R31E      2021  403.900000               368.786682   \nT32S R22E      2021  160.340000               200.964478   \nT32S R25E      2021  190.120000               170.062134   \nT32S R26E      2021  220.866667               188.235260   \n\n                     experiment_2_prediction  experiment_3_prediction  \\\nTOWNSHIP_RANGE YEAR                                                     \nT01N R02E      2021               121.115761                58.880062   \nT01N R11E      2021               191.187546               145.260483   \nT01S R03E      2021                89.398743                34.111828   \nT01S R07E      2021               116.964813                56.066540   \nT01S R10E      2021               146.275101               103.688248   \n...                                      ...                      ...   \nT31S R26E      2021               218.060379               229.395309   \nT31S R31E      2021               469.795868               381.163025   \nT32S R22E      2021               257.061676               194.516525   \nT32S R25E      2021               209.473526               238.012512   \nT32S R26E      2021               225.495667               208.150482   \n\n                     experiment_4_prediction  \nTOWNSHIP_RANGE YEAR                           \nT01N R02E      2021                55.766125  \nT01N R11E      2021               132.496689  \nT01S R03E      2021                28.095566  \nT01S R07E      2021                45.322628  \nT01S R10E      2021                92.169777  \n...                                      ...  \nT31S R26E      2021               228.809418  \nT31S R31E      2021               324.155060  \nT32S R22E      2021               186.001938  \nT32S R25E      2021               229.385040  \nT32S R26E      2021               192.373154  \n\n[96 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>GSE_GWE</th>\n      <th>experiment_1_prediction</th>\n      <th>experiment_2_prediction</th>\n      <th>experiment_3_prediction</th>\n      <th>experiment_4_prediction</th>\n    </tr>\n    <tr>\n      <th>TOWNSHIP_RANGE</th>\n      <th>YEAR</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>T01N R02E</th>\n      <th>2021</th>\n      <td>53.193636</td>\n      <td>36.336391</td>\n      <td>121.115761</td>\n      <td>58.880062</td>\n      <td>55.766125</td>\n    </tr>\n    <tr>\n      <th>T01N R11E</th>\n      <th>2021</th>\n      <td>107.955000</td>\n      <td>142.946442</td>\n      <td>191.187546</td>\n      <td>145.260483</td>\n      <td>132.496689</td>\n    </tr>\n    <tr>\n      <th>T01S R03E</th>\n      <th>2021</th>\n      <td>24.494538</td>\n      <td>18.849447</td>\n      <td>89.398743</td>\n      <td>34.111828</td>\n      <td>28.095566</td>\n    </tr>\n    <tr>\n      <th>T01S R07E</th>\n      <th>2021</th>\n      <td>38.644000</td>\n      <td>23.731907</td>\n      <td>116.964813</td>\n      <td>56.066540</td>\n      <td>45.322628</td>\n    </tr>\n    <tr>\n      <th>T01S R10E</th>\n      <th>2021</th>\n      <td>113.651250</td>\n      <td>104.674149</td>\n      <td>146.275101</td>\n      <td>103.688248</td>\n      <td>92.169777</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>T31S R26E</th>\n      <th>2021</th>\n      <td>173.915909</td>\n      <td>179.801483</td>\n      <td>218.060379</td>\n      <td>229.395309</td>\n      <td>228.809418</td>\n    </tr>\n    <tr>\n      <th>T31S R31E</th>\n      <th>2021</th>\n      <td>403.900000</td>\n      <td>368.786682</td>\n      <td>469.795868</td>\n      <td>381.163025</td>\n      <td>324.155060</td>\n    </tr>\n    <tr>\n      <th>T32S R22E</th>\n      <th>2021</th>\n      <td>160.340000</td>\n      <td>200.964478</td>\n      <td>257.061676</td>\n      <td>194.516525</td>\n      <td>186.001938</td>\n    </tr>\n    <tr>\n      <th>T32S R25E</th>\n      <th>2021</th>\n      <td>190.120000</td>\n      <td>170.062134</td>\n      <td>209.473526</td>\n      <td>238.012512</td>\n      <td>229.385040</td>\n    </tr>\n    <tr>\n      <th>T32S R26E</th>\n      <th>2021</th>\n      <td>220.866667</td>\n      <td>188.235260</td>\n      <td>225.495667</td>\n      <td>208.150482</td>\n      <td>192.373154</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "cell_id": "00016-6bf1168d-4e86-4aa5-8d5c-87bdf19dd540",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b042e2da-6536-449d-95b8-d85fa08825de' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "deepnote_notebook_id": "c8529be6-20eb-4908-b07e-49baddf8ecd5",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}