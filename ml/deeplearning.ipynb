{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import neptune.new as neptune\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from keras.optimizers import RMSprop, Adam, Adamax\n",
    "\n",
    "from lib.read_data import read_and_join_output_file\n",
    "#from lib.create_pipeline import create_transformation_pipeline\n",
    "from lib.deeplearning import create_transformation_pipelines\n",
    "from lib.transform_impute import convert_back_df\n",
    "from lib.split_data import train_test_group_time_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# During experiment we can try to use neptune.ai to log all the Tensorflow experiments results\n",
    "neptune_key = pickle.load(open(\"./neptune.pkl\", \"rb\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing the Dataset\n",
    "The train and test sets are split by Township-Ranges, i.e. some Township-Ranges data are either fully in the train or test set.\n",
    "The target value is the value of that variable for 2021\n",
    "Thus train/test sets are of shape (number of Township-Ranges, 7 years (2014-2020), the number of features).\n",
    "The input of 1 data point in the model is of shape (7x81\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "                     TOTALDRILLDEPTH_AVG  WELLYIELD_AVG  STATICWATERLEVEL_AVG  \\\nTOWNSHIP_RANGE YEAR                                                             \nT01N R03E      2014             0.097778       0.018246              0.037145   \n               2015             0.095238       0.021053              0.025042   \n               2016             0.114286       0.007916              0.022398   \n               2017             0.000000       0.013684              0.030885   \n               2018             0.083873       0.002474              0.034558   \n...                                  ...            ...                   ...   \nT32S R30E      2016             0.000000       0.000000              0.000000   \n               2017             0.000000       0.000000              0.000000   \n               2018             0.000000       0.000000              0.000000   \n               2019             0.000000       0.000000              0.000000   \n               2020             0.000000       0.000000              0.000000   \n\n                     TOPOFPERFORATEDINTERVAL_AVG  \\\nTOWNSHIP_RANGE YEAR                                \nT01N R03E      2014                     0.098039   \n               2015                     0.117647   \n               2016                     0.152614   \n               2017                     0.127451   \n               2018                     0.148257   \n...                                          ...   \nT32S R30E      2016                     0.000000   \n               2017                     0.000000   \n               2018                     0.000000   \n               2019                     0.000000   \n               2020                     0.000000   \n\n                     BOTTOMOFPERFORATEDINTERVAL_AVG  TOTALCOMPLETEDDEPTH_AVG  \\\nTOWNSHIP_RANGE YEAR                                                            \nT01N R03E      2014                        0.111111                 0.105856   \n               2015                        0.080460                 0.079848   \n               2016                        0.103768                 0.104880   \n               2017                        0.082375                 0.081749   \n               2018                        0.093934                 0.107605   \n...                                             ...                      ...   \nT32S R30E      2016                        0.000000                 0.000000   \n               2017                        0.000000                 0.000000   \n               2018                        0.000000                 0.000000   \n               2019                        0.000000                 0.000000   \n               2020                        0.000000                 0.000000   \n\n                     VEGETATION_BLUE_OAK-GRAY_PINE  \\\nTOWNSHIP_RANGE YEAR                                  \nT01N R03E      2014                       0.000037   \n               2015                       0.000037   \n               2016                       0.000037   \n               2017                       0.000037   \n               2018                       0.000037   \n...                                            ...   \nT32S R30E      2016                       0.033178   \n               2017                       0.033178   \n               2018                       0.033178   \n               2019                       0.033178   \n               2020                       0.033178   \n\n                     VEGETATION_CALIFORNIA_COAST_LIVE_OAK  \\\nTOWNSHIP_RANGE YEAR                                         \nT01N R03E      2014                              0.000137   \n               2015                              0.000137   \n               2016                              0.000137   \n               2017                              0.000137   \n               2018                              0.000137   \n...                                                   ...   \nT32S R30E      2016                              0.000000   \n               2017                              0.000000   \n               2018                              0.000000   \n               2019                              0.000000   \n               2020                              0.000000   \n\n                     VEGETATION_CANYON_LIVE_OAK  VEGETATION_HARD_CHAPARRAL  \\\nTOWNSHIP_RANGE YEAR                                                          \nT01N R03E      2014                    0.000000                   0.000386   \n               2015                    0.000000                   0.000386   \n               2016                    0.000000                   0.000386   \n               2017                    0.000000                   0.000386   \n               2018                    0.000000                   0.000386   \n...                                         ...                        ...   \nT32S R30E      2016                    0.002023                   0.003535   \n               2017                    0.002023                   0.003535   \n               2018                    0.002023                   0.003535   \n               2019                    0.002023                   0.003535   \n               2020                    0.002023                   0.003535   \n\n                     ...  POPULATION_DENSITY  PCT_OF_CAPACITY  \\\nTOWNSHIP_RANGE YEAR  ...                                        \nT01N R03E      2014  ...            0.252900         0.717075   \n               2015  ...            0.252799         0.717075   \n               2016  ...            0.250621         0.717075   \n               2017  ...            0.254669         0.717075   \n               2018  ...            0.256461         0.800728   \n...                  ...                 ...              ...   \nT32S R30E      2016  ...            0.004469         0.496289   \n               2017  ...            0.004457         0.496289   \n               2018  ...            0.004474         0.496289   \n               2019  ...            0.004491         0.580893   \n               2020  ...            0.004512         0.499980   \n\n                     GROUNDSURFACEELEVATION_AVG  AVERAGE_YEARLY_PRECIPITATION  \\\nTOWNSHIP_RANGE YEAR                                                             \nT01N R03E      2014                    0.023626                      0.163573   \n               2015                    0.018249                      0.217900   \n               2016                    0.024153                      0.209056   \n               2017                    0.023541                      0.213645   \n               2018                    0.020523                      0.181012   \n...                                         ...                           ...   \nT32S R30E      2016                    0.139007                      0.111564   \n               2017                    0.139007                      0.169284   \n               2018                    0.139007                      0.079747   \n               2019                    0.139007                      0.158678   \n               2020                    0.139007                      0.156231   \n\n                     SHORTAGE_COUNT   GSE_GWE  WELL_COUNT_AGRICULTURE  \\\nTOWNSHIP_RANGE YEAR                                                     \nT01N R03E      2014             0.0  0.043005                0.029412   \n               2015             0.0  0.050637                0.000000   \n               2016             0.0  0.035780                0.029412   \n               2017             0.0  0.033202                0.000000   \n               2018             0.0  0.030798                0.000000   \n...                             ...       ...                     ...   \nT32S R30E      2016             0.0  0.621728                0.000000   \n               2017             0.0  0.527907                0.000000   \n               2018             0.0  0.556283                0.000000   \n               2019             0.0  0.566892                0.000000   \n               2020             0.0  0.555112                0.000000   \n\n                     WELL_COUNT_DOMESTIC  WELL_COUNT_INDUSTRIAL  \\\nTOWNSHIP_RANGE YEAR                                               \nT01N R03E      2014             0.041667                    0.0   \n               2015             0.027778                    0.0   \n               2016             0.055556                    0.0   \n               2017             0.027778                    0.0   \n               2018             0.097222                    0.0   \n...                                  ...                    ...   \nT32S R30E      2016             0.000000                    0.0   \n               2017             0.000000                    0.0   \n               2018             0.000000                    0.0   \n               2019             0.000000                    0.0   \n               2020             0.000000                    0.0   \n\n                     WELL_COUNT_PUBLIC  \nTOWNSHIP_RANGE YEAR                     \nT01N R03E      2014                0.0  \n               2015                0.0  \n               2016                0.0  \n               2017                0.0  \n               2018                0.0  \n...                                ...  \nT32S R30E      2016                0.0  \n               2017                0.0  \n               2018                0.0  \n               2019                0.0  \n               2020                0.0  \n\n[2674 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>TOTALDRILLDEPTH_AVG</th>\n      <th>WELLYIELD_AVG</th>\n      <th>STATICWATERLEVEL_AVG</th>\n      <th>TOPOFPERFORATEDINTERVAL_AVG</th>\n      <th>BOTTOMOFPERFORATEDINTERVAL_AVG</th>\n      <th>TOTALCOMPLETEDDEPTH_AVG</th>\n      <th>VEGETATION_BLUE_OAK-GRAY_PINE</th>\n      <th>VEGETATION_CALIFORNIA_COAST_LIVE_OAK</th>\n      <th>VEGETATION_CANYON_LIVE_OAK</th>\n      <th>VEGETATION_HARD_CHAPARRAL</th>\n      <th>...</th>\n      <th>POPULATION_DENSITY</th>\n      <th>PCT_OF_CAPACITY</th>\n      <th>GROUNDSURFACEELEVATION_AVG</th>\n      <th>AVERAGE_YEARLY_PRECIPITATION</th>\n      <th>SHORTAGE_COUNT</th>\n      <th>GSE_GWE</th>\n      <th>WELL_COUNT_AGRICULTURE</th>\n      <th>WELL_COUNT_DOMESTIC</th>\n      <th>WELL_COUNT_INDUSTRIAL</th>\n      <th>WELL_COUNT_PUBLIC</th>\n    </tr>\n    <tr>\n      <th>TOWNSHIP_RANGE</th>\n      <th>YEAR</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">T01N R03E</th>\n      <th>2014</th>\n      <td>0.097778</td>\n      <td>0.018246</td>\n      <td>0.037145</td>\n      <td>0.098039</td>\n      <td>0.111111</td>\n      <td>0.105856</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.252900</td>\n      <td>0.717075</td>\n      <td>0.023626</td>\n      <td>0.163573</td>\n      <td>0.0</td>\n      <td>0.043005</td>\n      <td>0.029412</td>\n      <td>0.041667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>0.095238</td>\n      <td>0.021053</td>\n      <td>0.025042</td>\n      <td>0.117647</td>\n      <td>0.080460</td>\n      <td>0.079848</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.252799</td>\n      <td>0.717075</td>\n      <td>0.018249</td>\n      <td>0.217900</td>\n      <td>0.0</td>\n      <td>0.050637</td>\n      <td>0.000000</td>\n      <td>0.027778</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2016</th>\n      <td>0.114286</td>\n      <td>0.007916</td>\n      <td>0.022398</td>\n      <td>0.152614</td>\n      <td>0.103768</td>\n      <td>0.104880</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.250621</td>\n      <td>0.717075</td>\n      <td>0.024153</td>\n      <td>0.209056</td>\n      <td>0.0</td>\n      <td>0.035780</td>\n      <td>0.029412</td>\n      <td>0.055556</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>0.000000</td>\n      <td>0.013684</td>\n      <td>0.030885</td>\n      <td>0.127451</td>\n      <td>0.082375</td>\n      <td>0.081749</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.254669</td>\n      <td>0.717075</td>\n      <td>0.023541</td>\n      <td>0.213645</td>\n      <td>0.0</td>\n      <td>0.033202</td>\n      <td>0.000000</td>\n      <td>0.027778</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.083873</td>\n      <td>0.002474</td>\n      <td>0.034558</td>\n      <td>0.148257</td>\n      <td>0.093934</td>\n      <td>0.107605</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.256461</td>\n      <td>0.800728</td>\n      <td>0.020523</td>\n      <td>0.181012</td>\n      <td>0.0</td>\n      <td>0.030798</td>\n      <td>0.000000</td>\n      <td>0.097222</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">T32S R30E</th>\n      <th>2016</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004469</td>\n      <td>0.496289</td>\n      <td>0.139007</td>\n      <td>0.111564</td>\n      <td>0.0</td>\n      <td>0.621728</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004457</td>\n      <td>0.496289</td>\n      <td>0.139007</td>\n      <td>0.169284</td>\n      <td>0.0</td>\n      <td>0.527907</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004474</td>\n      <td>0.496289</td>\n      <td>0.139007</td>\n      <td>0.079747</td>\n      <td>0.0</td>\n      <td>0.556283</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2019</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004491</td>\n      <td>0.580893</td>\n      <td>0.139007</td>\n      <td>0.158678</td>\n      <td>0.0</td>\n      <td>0.566892</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004512</td>\n      <td>0.499980</td>\n      <td>0.139007</td>\n      <td>0.156231</td>\n      <td>0.0</td>\n      <td>0.555112</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2674 rows × 81 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "# Load the data from the ETL output files\n",
    "X = read_and_join_output_file()\n",
    "#X[\"WELL_COUNT\"] = X[\"WELL_COUNT_PUBLIC\"] + X[\"WELL_COUNT_AGRICULTURE\"] + X[\"WELL_COUNT_DOMESTIC\"] + X[\"WELL_COUNT_INDUSTRIAL\"]\n",
    "#X.drop(columns=[\"WELL_COUNT_PUBLIC\", \"WELL_COUNT_AGRICULTURE\", \"WELL_COUNT_DOMESTIC\", \"WELL_COUNT_INDUSTRIAL\"], inplace=True)\n",
    "# Split the data into a training and a test set\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_group_time_split(X, index=[\"TOWNSHIP_RANGE\", \"YEAR\"], group=\"TOWNSHIP_RANGE\", random_seed=RANDOM_SEED)\n",
    "# Create, fit and apply the data imputation pipeline to the training and test sets\n",
    "impute_pipeline, columns = create_transformation_pipelines(X_train_df)\n",
    "X_train_impute = impute_pipeline.fit_transform(X_train_df)\n",
    "X_test_impute = impute_pipeline.transform(X_test_df)\n",
    "# Convert the X_train and X_test back to dataframes\n",
    "X_train_impute_df = pd.DataFrame(X_train_impute, index=X_train_df.index, columns=columns)\n",
    "X_test_impute_df = pd.DataFrame(X_test_impute, index=X_test_df.index, columns=columns)\n",
    "# Keep only the GSE_GWE variable as the outcome variable\n",
    "scaler = MinMaxScaler()\n",
    "y_train = scaler.fit_transform(y_train_df[[\"GSE_GWE\"]])\n",
    "y_test = scaler.transform(y_test_df[[\"GSE_GWE\"]])\n",
    "X_train_impute_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Change the shape of the input array to (number of Township-Ranges, 7 years (2014-2020), the number of features)\n",
    "X_train = X_train_impute_df.values.reshape(len(X_train_impute_df.index.get_level_values(0).unique()), len(X_train_impute_df.index.get_level_values(1).unique()), X_train_impute_df.shape[1])\n",
    "X_test = X_test_impute_df.values.reshape(len(X_test_impute_df.index.get_level_values(0).unique()), len(X_test_impute_df.index.get_level_values(1).unique()), X_test_impute_df.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Checking the train, validation and test input (X) datasets sizes:\n",
      "Size of the X_train dataset: (382, 7, 81)\n",
      "Size of the X_test dataset: (96, 7, 81)\n",
      "====================================================================================================\n",
      "Checking the train, validation and test output (y) datasets sizes:\n",
      "Size of the y_train dataset: (382, 1)\n",
      "Size of the y_test dataset: (96, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"Checking the train, validation and test input (X) datasets sizes:\")\n",
    "print(f\"Size of the X_train dataset: {X_train.shape}\")\n",
    "#print(f\"Size of the X_val dataset: {X_val.shape}\")\n",
    "print(f\"Size of the X_test dataset: {X_test.shape}\")\n",
    "print(\"=\"*100)\n",
    "print(\"Checking the train, validation and test output (y) datasets sizes:\")\n",
    "print(f\"Size of the y_train dataset: {y_train.shape}\")\n",
    "#print(f\"Size of the y_val dataset: {y_val_df.shape}\")\n",
    "print(f\"Size of the y_test dataset: {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "results_df = y_test_df[[\"GSE_GWE\"]].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "nb_features = len(X_train_impute_df.columns)\n",
    "\n",
    "hyper_parameters = {\n",
    "    \"validation_split\": 0.05,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 30,\n",
    "    \"lstm_units\": 200,\n",
    "    \"lstm_activation\": \"tanh\",\n",
    "    \"output_activation\": \"linear\",\n",
    "    \"nb_features\": nb_features,\n",
    "    \"optimizer\": \"RMSprop\"\n",
    "}\n",
    "\n",
    "optimizer = {\n",
    "    \"RMSprop\": RMSprop(learning_rate=hyper_parameters[\"learning_rate\"]),\n",
    "    \"Adam\": Adam(learning_rate=hyper_parameters[\"learning_rate\"]),\n",
    "    \"Adamax\": Adamax(learning_rate=hyper_parameters[\"learning_rate\"])\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def evaluate_forecast(y_test_inverse, yhat_inverse):\n",
    "    mse_ = keras.metrics.MeanSquaredError()\n",
    "    mae_ = keras.metrics.MeanAbsoluteError()\n",
    "    rmse_ = keras.metrics.RootMeanSquaredError()\n",
    "    mae = mae_(y_test_inverse,yhat_inverse)\n",
    "    print('mae:', mae)\n",
    "    mse = mse_(y_test_inverse,yhat_inverse)\n",
    "    print('mse:', mse)\n",
    "    rmse = rmse_(y_test_inverse,yhat_inverse)\n",
    "    print('rmse:', rmse)\n",
    "    return mae, mse, rmse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 200)               225600    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,801\n",
      "Trainable params: 225,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(hyper_parameters[\"lstm_units\"], activation=hyper_parameters[\"lstm_activation\"], input_shape=(7, nb_features)))\n",
    "model1.add(Dense(1, activation=hyper_parameters[\"output_activation\"]))\n",
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-50\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 3s 133ms/step - loss: 0.0301 - val_loss: 0.0097\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.0077 - val_loss: 0.0134\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0049 - val_loss: 0.0198\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0044 - val_loss: 0.0074\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0042 - val_loss: 0.0171\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0042 - val_loss: 0.0085\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0042 - val_loss: 0.0086\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.0034 - val_loss: 0.0138\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0032 - val_loss: 0.0132\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0028 - val_loss: 0.0078\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0030 - val_loss: 0.0075\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0032 - val_loss: 0.0071\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.0020 - val_loss: 0.0095\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "mae: tf.Tensor(37.12118, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3138.0247, shape=(), dtype=float32)\n",
      "rmse: tf.Tensor(56.018074, shape=(), dtype=float32)\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 91 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 91 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-50\n"
     ]
    }
   ],
   "source": [
    "# Start experiment\n",
    "run = neptune.init(\n",
    "    project=\"milestone2-california-water-shortage/deeplearning-lstm\",\n",
    "    api_token=neptune_key,\n",
    "    name=\"Basic Model\",\n",
    "    tags=[\"WithDetailedWellCounts\", \"UnidirectionalLSTM\"]\n",
    ")\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')\n",
    "run['hyper-parameters'] = hyper_parameters\n",
    "\n",
    "model1.compile(loss=\"mse\", optimizer=optimizer[hyper_parameters[\"optimizer\"]])\n",
    "history = model1.fit(X_train, y_train,\n",
    "                     validation_split=hyper_parameters[\"validation_split\"],\n",
    "                     batch_size=hyper_parameters[\"batch_size\"],\n",
    "                     epochs=hyper_parameters[\"epochs\"],\n",
    "                     shuffle=True,\n",
    "                     callbacks=[neptune_cbk])\n",
    "yhat = model1.predict(X_test, verbose=0)\n",
    "yhat_inverse = scaler.inverse_transform(yhat)\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "results_df[\"experiment_1_prediction\"] = yhat_inverse\n",
    "mae, mse, rmse = evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "run[\"eval/mae\"] = mae\n",
    "run[\"eval/mse\"] = mse\n",
    "run[\"eval/rmse\"] = rmse\n",
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_4 (Bidirectio  (None, 400)              451200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 30)                12030     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 463,261\n",
      "Trainable params: 463,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters[\"dense_units\"] = 30\n",
    "hyper_parameters[\"dense_activation\"] = \"tanh\"\n",
    "hyper_parameters[\"dropout\"] = 0.02\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Bidirectional(LSTM(hyper_parameters[\"lstm_units\"], activation=hyper_parameters[\"lstm_activation\"]), input_shape=(7, nb_features)))\n",
    "model2.add(Dense(hyper_parameters[\"dense_units\"], activation=hyper_parameters[\"dense_activation\"]))\n",
    "model2.add(Dropout(hyper_parameters[\"dropout\"]))\n",
    "model2.add(Dense(1, activation=hyper_parameters[\"output_activation\"]))\n",
    "model2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-51\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 6s 272ms/step - loss: 0.0746 - val_loss: 0.0081\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 0.0121 - val_loss: 0.0059\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 3s 217ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 0.0049 - val_loss: 0.0227\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.0042 - val_loss: 0.0118\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 3s 218ms/step - loss: 0.0050 - val_loss: 0.0081\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 3s 278ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 0.0056 - val_loss: 0.0171\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 0.0040 - val_loss: 0.0088\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 2s 167ms/step - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 0.0037 - val_loss: 0.0122\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 3s 231ms/step - loss: 0.0032 - val_loss: 0.0068\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 0.0035 - val_loss: 0.0072\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 3s 264ms/step - loss: 0.0036 - val_loss: 0.0174\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.0033 - val_loss: 0.0113\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.0042 - val_loss: 0.0132\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 0.0035 - val_loss: 0.0167\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 3s 259ms/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 3s 210ms/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 0.0035 - val_loss: 0.0066\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 0.0030 - val_loss: 0.0108\n",
      "mae: tf.Tensor(50.12213, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(4345.498, shape=(), dtype=float32)\n",
      "rmse: tf.Tensor(65.920395, shape=(), dtype=float32)\n",
      "mae: tf.Tensor(50.12213, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(4345.498, shape=(), dtype=float32)\n",
      "rmse: tf.Tensor(65.920395, shape=(), dtype=float32)\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 80 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 80 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-51\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"milestone2-california-water-shortage/deeplearning-lstm\",\n",
    "    api_token=neptune_key,\n",
    "    name=\"Advanced Model 1\",\n",
    "    tags=[\"WithDetailedWellCounts\", \"BidirectionalLSTM\"]\n",
    ")\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')\n",
    "run['hyper-parameters'] = hyper_parameters\n",
    "\n",
    "model2.compile(loss=\"mse\", optimizer=optimizer[hyper_parameters[\"optimizer\"]])\n",
    "history = model2.fit(X_train, y_train,\n",
    "                     validation_split=hyper_parameters[\"validation_split\"],\n",
    "                     batch_size=hyper_parameters[\"batch_size\"],\n",
    "                     epochs=hyper_parameters[\"epochs\"],\n",
    "                     shuffle=True,\n",
    "                     callbacks=[neptune_cbk])\n",
    "yhat = model2.predict(X_test, verbose=0)\n",
    "yhat_inverse = scaler.inverse_transform(yhat)\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "results_df[\"experiment_2_prediction\"] = yhat_inverse\n",
    "evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "mae, mse, rmse = evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "run[\"eval/mae\"] = mae\n",
    "run[\"eval/mse\"] = mse\n",
    "run[\"eval/rmse\"] = rmse\n",
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "                        GSE_GWE  experiment_1_prediction  \\\nTOWNSHIP_RANGE YEAR                                        \nT01N R02E      2021   53.193636                36.336391   \nT01N R11E      2021  107.955000               142.946442   \nT01S R03E      2021   24.494538                18.849447   \nT01S R07E      2021   38.644000                23.731907   \nT01S R10E      2021  113.651250               104.674149   \n...                         ...                      ...   \nT31S R26E      2021  173.915909               179.801483   \nT31S R31E      2021  403.900000               368.786682   \nT32S R22E      2021  160.340000               200.964478   \nT32S R25E      2021  190.120000               170.062134   \nT32S R26E      2021  220.866667               188.235260   \n\n                     experiment_2_prediction  experiment_3_prediction  \\\nTOWNSHIP_RANGE YEAR                                                     \nT01N R02E      2021               121.115761                58.880062   \nT01N R11E      2021               191.187546               145.260483   \nT01S R03E      2021                89.398743                34.111828   \nT01S R07E      2021               116.964813                56.066540   \nT01S R10E      2021               146.275101               103.688248   \n...                                      ...                      ...   \nT31S R26E      2021               218.060379               229.395309   \nT31S R31E      2021               469.795868               381.163025   \nT32S R22E      2021               257.061676               194.516525   \nT32S R25E      2021               209.473526               238.012512   \nT32S R26E      2021               225.495667               208.150482   \n\n                     experiment_4_prediction  \nTOWNSHIP_RANGE YEAR                           \nT01N R02E      2021                55.766125  \nT01N R11E      2021               132.496689  \nT01S R03E      2021                28.095566  \nT01S R07E      2021                45.322628  \nT01S R10E      2021                92.169777  \n...                                      ...  \nT31S R26E      2021               228.809418  \nT31S R31E      2021               324.155060  \nT32S R22E      2021               186.001938  \nT32S R25E      2021               229.385040  \nT32S R26E      2021               192.373154  \n\n[96 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>GSE_GWE</th>\n      <th>experiment_1_prediction</th>\n      <th>experiment_2_prediction</th>\n      <th>experiment_3_prediction</th>\n      <th>experiment_4_prediction</th>\n    </tr>\n    <tr>\n      <th>TOWNSHIP_RANGE</th>\n      <th>YEAR</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>T01N R02E</th>\n      <th>2021</th>\n      <td>53.193636</td>\n      <td>36.336391</td>\n      <td>121.115761</td>\n      <td>58.880062</td>\n      <td>55.766125</td>\n    </tr>\n    <tr>\n      <th>T01N R11E</th>\n      <th>2021</th>\n      <td>107.955000</td>\n      <td>142.946442</td>\n      <td>191.187546</td>\n      <td>145.260483</td>\n      <td>132.496689</td>\n    </tr>\n    <tr>\n      <th>T01S R03E</th>\n      <th>2021</th>\n      <td>24.494538</td>\n      <td>18.849447</td>\n      <td>89.398743</td>\n      <td>34.111828</td>\n      <td>28.095566</td>\n    </tr>\n    <tr>\n      <th>T01S R07E</th>\n      <th>2021</th>\n      <td>38.644000</td>\n      <td>23.731907</td>\n      <td>116.964813</td>\n      <td>56.066540</td>\n      <td>45.322628</td>\n    </tr>\n    <tr>\n      <th>T01S R10E</th>\n      <th>2021</th>\n      <td>113.651250</td>\n      <td>104.674149</td>\n      <td>146.275101</td>\n      <td>103.688248</td>\n      <td>92.169777</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>T31S R26E</th>\n      <th>2021</th>\n      <td>173.915909</td>\n      <td>179.801483</td>\n      <td>218.060379</td>\n      <td>229.395309</td>\n      <td>228.809418</td>\n    </tr>\n    <tr>\n      <th>T31S R31E</th>\n      <th>2021</th>\n      <td>403.900000</td>\n      <td>368.786682</td>\n      <td>469.795868</td>\n      <td>381.163025</td>\n      <td>324.155060</td>\n    </tr>\n    <tr>\n      <th>T32S R22E</th>\n      <th>2021</th>\n      <td>160.340000</td>\n      <td>200.964478</td>\n      <td>257.061676</td>\n      <td>194.516525</td>\n      <td>186.001938</td>\n    </tr>\n    <tr>\n      <th>T32S R25E</th>\n      <th>2021</th>\n      <td>190.120000</td>\n      <td>170.062134</td>\n      <td>209.473526</td>\n      <td>238.012512</td>\n      <td>229.385040</td>\n    </tr>\n    <tr>\n      <th>T32S R26E</th>\n      <th>2021</th>\n      <td>220.866667</td>\n      <td>188.235260</td>\n      <td>225.495667</td>\n      <td>208.150482</td>\n      <td>192.373154</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}