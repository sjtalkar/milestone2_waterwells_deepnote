{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import neptune.new as neptune\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from keras.optimizers import RMSprop, Adam, Adamax\n",
    "\n",
    "from lib.read_data import read_and_join_output_file\n",
    "from lib.create_pipeline import create_transformation_pipeline\n",
    "from lib.transform_impute import convert_back_df\n",
    "from lib.split_data import train_test_group_time_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# During experiment we can try to use neptune.ai to log all the Tensorflow experiments results\n",
    "neptune_key = pickle.load(open(\"./neptune.pkl\", \"rb\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing the Dataset\n",
    "The train and test sets are split by Township-Ranges, i.e. some Township-Ranges data are either fully in the train or test set.\n",
    "The target value is the value of that variable for 2021\n",
    "Thus train/test sets are of shape (number of Township-Ranges, 7 years (2014-2020), the number of features).\n",
    "The input of 1 data point in the model is of shape (7x81\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "                     TOTALDRILLDEPTH_AVG  WELLYIELD_AVG  STATICWATERLEVEL_AVG  \\\nTOWNSHIP_RANGE YEAR                                                             \nT01N R03E      2014             0.097778       0.018246              0.037145   \n               2015             0.095238       0.021053              0.025042   \n               2016             0.114286       0.007916              0.022398   \n               2017             0.000000       0.013684              0.030885   \n               2018             0.083873       0.002474              0.034558   \n...                                  ...            ...                   ...   \nT32S R30E      2016             0.000000       0.000000              0.000000   \n               2017             0.000000       0.000000              0.000000   \n               2018             0.000000       0.000000              0.000000   \n               2019             0.000000       0.000000              0.000000   \n               2020             0.000000       0.000000              0.000000   \n\n                     TOPOFPERFORATEDINTERVAL_AVG  \\\nTOWNSHIP_RANGE YEAR                                \nT01N R03E      2014                     0.098039   \n               2015                     0.117647   \n               2016                     0.152614   \n               2017                     0.127451   \n               2018                     0.148257   \n...                                          ...   \nT32S R30E      2016                     0.000000   \n               2017                     0.000000   \n               2018                     0.000000   \n               2019                     0.000000   \n               2020                     0.000000   \n\n                     BOTTOMOFPERFORATEDINTERVAL_AVG  TOTALCOMPLETEDDEPTH_AVG  \\\nTOWNSHIP_RANGE YEAR                                                            \nT01N R03E      2014                        0.111111                 0.105856   \n               2015                        0.080460                 0.079848   \n               2016                        0.103768                 0.104880   \n               2017                        0.082375                 0.081749   \n               2018                        0.093934                 0.107605   \n...                                             ...                      ...   \nT32S R30E      2016                        0.000000                 0.000000   \n               2017                        0.000000                 0.000000   \n               2018                        0.000000                 0.000000   \n               2019                        0.000000                 0.000000   \n               2020                        0.000000                 0.000000   \n\n                     VEGETATION_BLUE_OAK-GRAY_PINE  \\\nTOWNSHIP_RANGE YEAR                                  \nT01N R03E      2014                       0.000037   \n               2015                       0.000037   \n               2016                       0.000037   \n               2017                       0.000037   \n               2018                       0.000037   \n...                                            ...   \nT32S R30E      2016                       0.033178   \n               2017                       0.033178   \n               2018                       0.033178   \n               2019                       0.033178   \n               2020                       0.033178   \n\n                     VEGETATION_CALIFORNIA_COAST_LIVE_OAK  \\\nTOWNSHIP_RANGE YEAR                                         \nT01N R03E      2014                              0.000137   \n               2015                              0.000137   \n               2016                              0.000137   \n               2017                              0.000137   \n               2018                              0.000137   \n...                                                   ...   \nT32S R30E      2016                              0.000000   \n               2017                              0.000000   \n               2018                              0.000000   \n               2019                              0.000000   \n               2020                              0.000000   \n\n                     VEGETATION_CANYON_LIVE_OAK  VEGETATION_HARD_CHAPARRAL  \\\nTOWNSHIP_RANGE YEAR                                                          \nT01N R03E      2014                    0.000000                   0.000386   \n               2015                    0.000000                   0.000386   \n               2016                    0.000000                   0.000386   \n               2017                    0.000000                   0.000386   \n               2018                    0.000000                   0.000386   \n...                                         ...                        ...   \nT32S R30E      2016                    0.002023                   0.003535   \n               2017                    0.002023                   0.003535   \n               2018                    0.002023                   0.003535   \n               2019                    0.002023                   0.003535   \n               2020                    0.002023                   0.003535   \n\n                     ...  POPULATION_DENSITY  PCT_OF_CAPACITY  \\\nTOWNSHIP_RANGE YEAR  ...                                        \nT01N R03E      2014  ...            0.252900         0.717075   \n               2015  ...            0.252799         0.717075   \n               2016  ...            0.250621         0.717075   \n               2017  ...            0.254669         0.717075   \n               2018  ...            0.256461         0.800728   \n...                  ...                 ...              ...   \nT32S R30E      2016  ...            0.004469         0.496289   \n               2017  ...            0.004457         0.496289   \n               2018  ...            0.004474         0.496289   \n               2019  ...            0.004491         0.580893   \n               2020  ...            0.004512         0.499980   \n\n                     GROUNDSURFACEELEVATION_AVG  AVERAGE_YEARLY_PRECIPITATION  \\\nTOWNSHIP_RANGE YEAR                                                             \nT01N R03E      2014                    0.023626                      0.163573   \n               2015                    0.018249                      0.217900   \n               2016                    0.024153                      0.209056   \n               2017                    0.023541                      0.213645   \n               2018                    0.020523                      0.181012   \n...                                         ...                           ...   \nT32S R30E      2016                    0.139007                      0.111564   \n               2017                    0.139007                      0.169284   \n               2018                    0.139007                      0.079747   \n               2019                    0.139007                      0.158678   \n               2020                    0.139007                      0.156231   \n\n                     SHORTAGE_COUNT   GSE_GWE  WELL_COUNT_AGRICULTURE  \\\nTOWNSHIP_RANGE YEAR                                                     \nT01N R03E      2014             0.0  0.043005                0.029412   \n               2015             0.0  0.050637                0.000000   \n               2016             0.0  0.035780                0.029412   \n               2017             0.0  0.033202                0.000000   \n               2018             0.0  0.030798                0.000000   \n...                             ...       ...                     ...   \nT32S R30E      2016             0.0  0.621728                0.000000   \n               2017             0.0  0.527907                0.000000   \n               2018             0.0  0.556283                0.000000   \n               2019             0.0  0.566892                0.000000   \n               2020             0.0  0.555112                0.000000   \n\n                     WELL_COUNT_DOMESTIC  WELL_COUNT_INDUSTRIAL  \\\nTOWNSHIP_RANGE YEAR                                               \nT01N R03E      2014             0.041667                    0.0   \n               2015             0.027778                    0.0   \n               2016             0.055556                    0.0   \n               2017             0.027778                    0.0   \n               2018             0.097222                    0.0   \n...                                  ...                    ...   \nT32S R30E      2016             0.000000                    0.0   \n               2017             0.000000                    0.0   \n               2018             0.000000                    0.0   \n               2019             0.000000                    0.0   \n               2020             0.000000                    0.0   \n\n                     WELL_COUNT_PUBLIC  \nTOWNSHIP_RANGE YEAR                     \nT01N R03E      2014                0.0  \n               2015                0.0  \n               2016                0.0  \n               2017                0.0  \n               2018                0.0  \n...                                ...  \nT32S R30E      2016                0.0  \n               2017                0.0  \n               2018                0.0  \n               2019                0.0  \n               2020                0.0  \n\n[2674 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>TOTALDRILLDEPTH_AVG</th>\n      <th>WELLYIELD_AVG</th>\n      <th>STATICWATERLEVEL_AVG</th>\n      <th>TOPOFPERFORATEDINTERVAL_AVG</th>\n      <th>BOTTOMOFPERFORATEDINTERVAL_AVG</th>\n      <th>TOTALCOMPLETEDDEPTH_AVG</th>\n      <th>VEGETATION_BLUE_OAK-GRAY_PINE</th>\n      <th>VEGETATION_CALIFORNIA_COAST_LIVE_OAK</th>\n      <th>VEGETATION_CANYON_LIVE_OAK</th>\n      <th>VEGETATION_HARD_CHAPARRAL</th>\n      <th>...</th>\n      <th>POPULATION_DENSITY</th>\n      <th>PCT_OF_CAPACITY</th>\n      <th>GROUNDSURFACEELEVATION_AVG</th>\n      <th>AVERAGE_YEARLY_PRECIPITATION</th>\n      <th>SHORTAGE_COUNT</th>\n      <th>GSE_GWE</th>\n      <th>WELL_COUNT_AGRICULTURE</th>\n      <th>WELL_COUNT_DOMESTIC</th>\n      <th>WELL_COUNT_INDUSTRIAL</th>\n      <th>WELL_COUNT_PUBLIC</th>\n    </tr>\n    <tr>\n      <th>TOWNSHIP_RANGE</th>\n      <th>YEAR</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">T01N R03E</th>\n      <th>2014</th>\n      <td>0.097778</td>\n      <td>0.018246</td>\n      <td>0.037145</td>\n      <td>0.098039</td>\n      <td>0.111111</td>\n      <td>0.105856</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.252900</td>\n      <td>0.717075</td>\n      <td>0.023626</td>\n      <td>0.163573</td>\n      <td>0.0</td>\n      <td>0.043005</td>\n      <td>0.029412</td>\n      <td>0.041667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>0.095238</td>\n      <td>0.021053</td>\n      <td>0.025042</td>\n      <td>0.117647</td>\n      <td>0.080460</td>\n      <td>0.079848</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.252799</td>\n      <td>0.717075</td>\n      <td>0.018249</td>\n      <td>0.217900</td>\n      <td>0.0</td>\n      <td>0.050637</td>\n      <td>0.000000</td>\n      <td>0.027778</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2016</th>\n      <td>0.114286</td>\n      <td>0.007916</td>\n      <td>0.022398</td>\n      <td>0.152614</td>\n      <td>0.103768</td>\n      <td>0.104880</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.250621</td>\n      <td>0.717075</td>\n      <td>0.024153</td>\n      <td>0.209056</td>\n      <td>0.0</td>\n      <td>0.035780</td>\n      <td>0.029412</td>\n      <td>0.055556</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>0.000000</td>\n      <td>0.013684</td>\n      <td>0.030885</td>\n      <td>0.127451</td>\n      <td>0.082375</td>\n      <td>0.081749</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.254669</td>\n      <td>0.717075</td>\n      <td>0.023541</td>\n      <td>0.213645</td>\n      <td>0.0</td>\n      <td>0.033202</td>\n      <td>0.000000</td>\n      <td>0.027778</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.083873</td>\n      <td>0.002474</td>\n      <td>0.034558</td>\n      <td>0.148257</td>\n      <td>0.093934</td>\n      <td>0.107605</td>\n      <td>0.000037</td>\n      <td>0.000137</td>\n      <td>0.000000</td>\n      <td>0.000386</td>\n      <td>...</td>\n      <td>0.256461</td>\n      <td>0.800728</td>\n      <td>0.020523</td>\n      <td>0.181012</td>\n      <td>0.0</td>\n      <td>0.030798</td>\n      <td>0.000000</td>\n      <td>0.097222</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">T32S R30E</th>\n      <th>2016</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004469</td>\n      <td>0.496289</td>\n      <td>0.139007</td>\n      <td>0.111564</td>\n      <td>0.0</td>\n      <td>0.621728</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004457</td>\n      <td>0.496289</td>\n      <td>0.139007</td>\n      <td>0.169284</td>\n      <td>0.0</td>\n      <td>0.527907</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004474</td>\n      <td>0.496289</td>\n      <td>0.139007</td>\n      <td>0.079747</td>\n      <td>0.0</td>\n      <td>0.556283</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2019</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004491</td>\n      <td>0.580893</td>\n      <td>0.139007</td>\n      <td>0.158678</td>\n      <td>0.0</td>\n      <td>0.566892</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033178</td>\n      <td>0.000000</td>\n      <td>0.002023</td>\n      <td>0.003535</td>\n      <td>...</td>\n      <td>0.004512</td>\n      <td>0.499980</td>\n      <td>0.139007</td>\n      <td>0.156231</td>\n      <td>0.0</td>\n      <td>0.555112</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2674 rows × 81 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "# Load the data from the ETL output files\n",
    "X = read_and_join_output_file()\n",
    "#X[\"WELL_COUNT\"] = X[\"WELL_COUNT_PUBLIC\"] + X[\"WELL_COUNT_AGRICULTURE\"] + X[\"WELL_COUNT_DOMESTIC\"] + X[\"WELL_COUNT_INDUSTRIAL\"]\n",
    "#X.drop(columns=[\"WELL_COUNT_PUBLIC\", \"WELL_COUNT_AGRICULTURE\", \"WELL_COUNT_DOMESTIC\", \"WELL_COUNT_INDUSTRIAL\"], inplace=True)\n",
    "# Split the data into a training and a test set\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_group_time_split(X, index=[\"TOWNSHIP_RANGE\", \"YEAR\"], group=\"TOWNSHIP_RANGE\", random_seed=RANDOM_SEED)\n",
    "# Create, fit and apply the data imputation pipeline to the training and test sets\n",
    "impute_pipeline = create_transformation_pipeline(X_train_df, scaler = MinMaxScaler())\n",
    "X_train_impute = impute_pipeline.fit_transform(X_train_df)\n",
    "X_test_impute = impute_pipeline.fit_transform(X_test_df)\n",
    "# Convert the X_train and X_test back to dataframes\n",
    "X_train_impute_df = convert_back_df(X_train_impute, impute_pipeline, X_train_df)\n",
    "X_test_impute_df = convert_back_df(X_test_impute, impute_pipeline, X_test_df)\n",
    "# Keep only the GSE_GWE variable as the outcome variable\n",
    "scaler = MinMaxScaler()\n",
    "y_train = scaler.fit_transform(y_train_df[[\"GSE_GWE\"]])\n",
    "y_test = scaler.transform(y_test_df[[\"GSE_GWE\"]])\n",
    "X_train_impute_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Change the shape of the input array to (number of Township-Ranges, 7 years (2014-2020), the number of features)\n",
    "X_train = X_train_impute_df.values.reshape(len(X_train_impute_df.index.get_level_values(0).unique()), len(X_train_impute_df.index.get_level_values(1).unique()), X_train_impute_df.shape[1])\n",
    "X_test = X_test_impute_df.values.reshape(len(X_test_impute_df.index.get_level_values(0).unique()), len(X_test_impute_df.index.get_level_values(1).unique()), X_test_impute_df.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Checking the train, validation and test input (X) datasets sizes:\n",
      "Size of the X_train dataset: (382, 7, 81)\n",
      "Size of the X_test dataset: (96, 7, 81)\n",
      "====================================================================================================\n",
      "Checking the train, validation and test output (y) datasets sizes:\n",
      "Size of the y_train dataset: (382, 1)\n",
      "Size of the y_test dataset: (96, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"Checking the train, validation and test input (X) datasets sizes:\")\n",
    "print(f\"Size of the X_train dataset: {X_train.shape}\")\n",
    "#print(f\"Size of the X_val dataset: {X_val.shape}\")\n",
    "print(f\"Size of the X_test dataset: {X_test.shape}\")\n",
    "print(\"=\"*100)\n",
    "print(\"Checking the train, validation and test output (y) datasets sizes:\")\n",
    "print(f\"Size of the y_train dataset: {y_train.shape}\")\n",
    "#print(f\"Size of the y_val dataset: {y_val_df.shape}\")\n",
    "print(f\"Size of the y_test dataset: {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "results_df = y_test_df[[\"GSE_GWE\"]].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "nb_features = len(X_train_impute_df.columns)\n",
    "\n",
    "hyper_parameters = {\n",
    "    \"validation_split\": 0.05,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 30,\n",
    "    \"lstm_units\": 200,\n",
    "    \"output_activation\": \"linear\",\n",
    "}\n",
    "\n",
    "adam_optimizer = Adam(learning_rate=hyper_parameters[\"learning_rate\"])\n",
    "rms_optimizer = RMSprop(learning_rate=hyper_parameters[\"learning_rate\"])\n",
    "adamax_optimizer = Adamax(learning_rate=hyper_parameters[\"learning_rate\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def evaluate_forecast(y_test_inverse, yhat_inverse):\n",
    "    mse_ = keras.metrics.MeanSquaredError()\n",
    "    mae_ = keras.metrics.MeanAbsoluteError()\n",
    "    rmse_ = keras.metrics.RootMeanSquaredError()\n",
    "    mae = mae_(y_test_inverse,yhat_inverse)\n",
    "    print('mae:', mae)\n",
    "    mse = mse_(y_test_inverse,yhat_inverse)\n",
    "    print('mse:', mse)\n",
    "    rmse = rmse_(y_test_inverse,yhat_inverse)\n",
    "    print('rmse:', rmse)\n",
    "    return mae, mse, rmse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 200)               225600    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,801\n",
      "Trainable params: 225,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(hyper_parameters[\"lstm_units\"], input_shape=(7, nb_features)))\n",
    "model1.add(Dense(1, activation=hyper_parameters[\"output_activation\"]))\n",
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-1\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 3s 94ms/step - loss: 0.0283 - val_loss: 0.0088\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0100 - val_loss: 0.0158\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0046 - val_loss: 0.0277\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0057 - val_loss: 0.0098\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0032 - val_loss: 0.0109\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0043 - val_loss: 0.0112\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0031 - val_loss: 0.0069\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0033 - val_loss: 0.0066\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0024 - val_loss: 0.0115\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0017 - val_loss: 0.0097\n",
      "mae: tf.Tensor(58.845993, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(6285.3867, shape=(), dtype=float32)\n",
      "rmse: tf.Tensor(79.28043, shape=(), dtype=float32)\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 207 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 207 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-1\n"
     ]
    }
   ],
   "source": [
    "# Start experiment\n",
    "run = neptune.init(\n",
    "    project=\"milestone2-california-water-shortage/deeplearning-lstm\",\n",
    "    api_token=neptune_key,\n",
    "    name=\"Basic Model\",\n",
    "    tags=[\"WithDetailedWellCounts\"]\n",
    ")\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')\n",
    "hyper_parameters[\"optimizer\"] = \"RMSprop\"\n",
    "run['hyper-parameters'] = hyper_parameters\n",
    "\n",
    "model1.compile(loss=\"mse\", optimizer=rms_optimizer)\n",
    "history = model1.fit(X_train, y_train,\n",
    "                     validation_split=hyper_parameters[\"validation_split\"],\n",
    "                     batch_size=hyper_parameters[\"batch_size\"],\n",
    "                     epochs=hyper_parameters[\"epochs\"],\n",
    "                     shuffle=True,\n",
    "                     callbacks=[neptune_cbk])\n",
    "yhat = model1.predict(X_test, verbose=0)\n",
    "yhat_inverse = scaler.inverse_transform(yhat)\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "results_df[\"experiment_1_prediction\"] = yhat_inverse\n",
    "mae, mse, rmse = evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "run[\"eval/mae\"] = mae\n",
    "run[\"eval/mse\"] = mse\n",
    "run[\"eval/rmse\"] = rmse\n",
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirectio  (None, 400)              451200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                8020      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 459,241\n",
      "Trainable params: 459,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters[\"dense_units\"] = 20\n",
    "hyper_parameters[\"dropout\"] = 0.02\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Bidirectional(LSTM(hyper_parameters[\"lstm_units\"]), input_shape=(7, nb_features)))\n",
    "model2.add(Dense(hyper_parameters[\"dense_units\"], activation=\"tanh\"))\n",
    "model2.add(Dropout(hyper_parameters[\"dropout\"]))\n",
    "model2.add(Dense(1, activation=hyper_parameters[\"output_activation\"]))\n",
    "model2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-2\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 4s 118ms/step - loss: 0.0330 - val_loss: 0.0115\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0101 - val_loss: 0.0040\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0038 - val_loss: 0.0095\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0037 - val_loss: 0.0099\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0032 - val_loss: 0.0090\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0036 - val_loss: 0.0069\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0024 - val_loss: 0.0076\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0016 - val_loss: 0.0039\n",
      "mae: tf.Tensor(38.009636, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3686.1865, shape=(), dtype=float32)\n",
      "rmse: tf.Tensor(60.713974, shape=(), dtype=float32)\n",
      "mae: tf.Tensor(38.009636, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3686.1865, shape=(), dtype=float32)\n",
      "rmse: tf.Tensor(60.713974, shape=(), dtype=float32)\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 195 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 195 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-2\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"milestone2-california-water-shortage/deeplearning-lstm\",\n",
    "    api_token=neptune_key,\n",
    "    name=\"Advanced Model 1\",\n",
    "    tags=[\"WithDetailedWellCounts\"]\n",
    ")\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')\n",
    "hyper_parameters[\"optimizer\"] = \"Adam\"\n",
    "run['hyper-parameters'] = hyper_parameters\n",
    "\n",
    "model2.compile(loss=\"mse\", optimizer=adam_optimizer)\n",
    "history = model2.fit(X_train, y_train,\n",
    "                     validation_split=hyper_parameters[\"validation_split\"],\n",
    "                     batch_size=hyper_parameters[\"batch_size\"],\n",
    "                     epochs=hyper_parameters[\"epochs\"],\n",
    "                     shuffle=True,\n",
    "                     callbacks=[neptune_cbk])\n",
    "yhat = model2.predict(X_test, verbose=0)\n",
    "yhat_inverse = scaler.inverse_transform(yhat)\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "results_df[\"experiment_2_prediction\"] = yhat_inverse\n",
    "evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "mae, mse, rmse = evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "run[\"eval/mae\"] = mae\n",
    "run[\"eval/mse\"] = mse\n",
    "run[\"eval/rmse\"] = rmse\n",
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/milestone2-california-water-shortage/deeplearning-lstm/e/DEEPLSTM-3\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"milestone2-california-water-shortage/deeplearning-lstm\",\n",
    "    api_token=neptune_key,\n",
    "    name=\"Advanced Model 1\",\n",
    "    tags=[\"WithDetailedWellCounts\"]\n",
    ")\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')\n",
    "hyper_parameters[\"optimizer\"] = \"RMSprop\"\n",
    "run['hyper-parameters'] = hyper_parameters\n",
    "\n",
    "model2.compile(loss=\"mse\", optimizer=rms_optimizer)\n",
    "history = model2.fit(X_train, y_train,\n",
    "                     validation_split=hyper_parameters[\"validation_split\"],\n",
    "                     batch_size=hyper_parameters[\"batch_size\"],\n",
    "                     epochs=hyper_parameters[\"epochs\"],\n",
    "                     shuffle=True,\n",
    "                     callbacks=[neptune_cbk])\n",
    "yhat = model2.predict(X_test, verbose=0)\n",
    "yhat_inverse = scaler.inverse_transform(yhat)\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "results_df[\"experiment_3_prediction\"] = yhat_inverse\n",
    "evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "mae, mse, rmse = evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "run[\"eval/mae\"] = mae\n",
    "run[\"eval/mse\"] = mse\n",
    "run[\"eval/rmse\"] = rmse\n",
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run = neptune.init(\n",
    "    project=\"milestone2-california-water-shortage/deeplearning-lstm\",\n",
    "    api_token=neptune_key,\n",
    "    name=\"Advanced Model 1\",\n",
    "    tags=[\"WithDetailedWellCounts\"]\n",
    ")\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')\n",
    "hyper_parameters[\"optimizer\"] = \"Adamx\"\n",
    "run['hyper-parameters'] = hyper_parameters\n",
    "\n",
    "model2.compile(loss=\"mse\", optimizer=adamax_optimizer)\n",
    "history = model2.fit(X_train, y_train,\n",
    "                     validation_split=hyper_parameters[\"validation_split\"],\n",
    "                     batch_size=hyper_parameters[\"batch_size\"],\n",
    "                     epochs=hyper_parameters[\"epochs\"],\n",
    "                     shuffle=True,\n",
    "                     callbacks=[neptune_cbk])\n",
    "yhat = model2.predict(X_test, verbose=0)\n",
    "yhat_inverse = scaler.inverse_transform(yhat)\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "results_df[\"experiment_4_prediction\"] = yhat_inverse\n",
    "evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "mae, mse, rmse = evaluate_forecast(y_test_inverse, yhat_inverse)\n",
    "run[\"eval/mae\"] = mae\n",
    "run[\"eval/mse\"] = mse\n",
    "run[\"eval/rmse\"] = rmse\n",
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}