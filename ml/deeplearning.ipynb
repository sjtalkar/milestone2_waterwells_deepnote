{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training, Testing and Predicting With an LSTM Model\n",
    "In the notebook `ml/deeplearning_tuning.ipynb` we performed a Bayesian hyperparameter tuning to find the best hyperparameters for 3 potential LSTM models architectures.\n",
    "In this notebook we:\n",
    "1. train each of the 3 LSTM architectures with their best hyperparameters\n",
    "2. tested their results on the test dataset to select the best model\n",
    "3. analyze the sensibility of the best model to hyperparameters\n",
    "4. use the best model to predict the groundwater depth for the year 2022.\n",
    "## Multiple Multivariate Time Series Predictions with LSTM\n",
    "The dataset is made of 478 Township-Ranges, each containing a multivariate (80 features) time series (data between 2014 to 2021). This dataset can thus be seen as a 3 dimensional dataset of\n",
    "$478\\ TownshipRanges\\ *\\ 8\\ time stamps\\ *\\ 80\\ features$\n",
    "The objective is to predict the 2022 target value of `GSE_GWE` (Ground Surface Elevation to Groundwater Water Elevation - Depth to groundwater elevation in feet below ground surface) for each Township-Range.\n",
    "\n",
    "LSTMs are used for time series and NLP because they are both sequential data and depend on previous states.\n",
    "The future prediction *Y(t+n+1)* depends not only on the last state *X1(t+n), ..., Y(t+n)*, not only on past values of the feature *Y(t+1), ..., Y(t+n)*, but on the entire past states sequence.\n",
    "\n",
    "![Multi-Variate Multi TImes-Series Predictions with LSTM - Training and Prediction](../doc/images/lstm_inputs_outputs.jpg)\n",
    "\n",
    "During training and predictions:\n",
    "* Township-Ranges are passed into the model one by one\n",
    "* each cell in the LSM neural network receives a Township-Range state for a specific year (the state of the Township-Range at a specific position in the series)\n",
    "* each state (year) in the series is represented by a multidimensional vector of all 80 features (including the target feature Y `GSE_GWE`)\n",
    "\n",
    "The output is the Township-Ranges next year's value for the specific feature Y `GSE_GWE`. The model is trained on 2014-2020 (7 years) data to predict 2021.\n",
    "During inference the last 7 years (2015-2021) of data are passed as input to predict the 2022 value.\n",
    "\n",
    "![Multi-Variate Multi TImes-Series Predictions with LSTM - Cells Inputs](../doc/images/lstm_table_to_cells.jpg)"
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "0ecc9d30-6818-4805-89ba-0fc40048f951",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 1821.609375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00001-45ec143e-17c1-4779-a233-9d45db5638da",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "18561438",
    "execution_start": 1663514013567,
    "execution_millis": 3,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 94
   },
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00002-23c9276e-61cc-4602-9f7d-f63ae60e4497",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bc5de647",
    "execution_start": 1663514013573,
    "execution_millis": 4979,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 464.75
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from lib.township_range import TownshipRanges\n",
    "from lib.read_data import read_and_join_output_file\n",
    "from lib.deeplearning import get_train_test_datasets, get_sets_shapes, get_data_for_prediction, evaluate_forecast, combine_all_target_years, get_year_to_year_differences\n",
    "from lib.viz import view_trs_side_by_side, draw_hyperparameters_distribution, draw_line_chart\n",
    "\n",
    "import tensorflow\n",
    "from sklearn import set_config\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, RepeatVector\n",
    "from keras.optimizers import Adam"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00003-893eb8de-b2f4-4a5d-996a-6607604022f8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "65465ae4",
    "execution_start": 1663514018555,
    "execution_millis": 7,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 130
   },
   "source": [
    "RANDOM_SEED = 31\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tensorflow.random.set_seed(RANDOM_SEED)"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00004-298dfc55-4c61-44a9-a815-33f7a7010061",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2a96f01a",
    "execution_start": 1663514018568,
    "execution_millis": 4,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 171.75
   },
   "source": [
    "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing the Dataset\n",
    "### The Train-Test Split\n",
    "To fit our dataset and objective, as well as LSTM neural networks architecture we perform the train test split as follows:\n",
    "* Training and Test sets will be split by Township-Ranges. I.e., some Township-Ranges will have all their 2014-2021 data points in the training set, some others will be in the test set.\n",
    "* The model will be trained based on the 2014-2020 data for all features - including the target feature - with the training target being the 2021 value of the target feature.\n",
    "\n",
    "With such a method, unlike a simple time series forecasting where the target feature is forecasted only based on its past value, we allow past value of other features (in our case cultivated crops, precipitations, population density, number of wells drilled) to influence the future value of the target feature.\n",
    "\n",
    "![Train-Test Split](../doc/images/lstm-train-test-split.jpg)\n",
    "\n",
    "We do not create a validation dataset as we use Keras internal cross-validation mechanism to shuffle the data points (i.e., the Township-Ranges) and keep some for the validation at each training epoch.\n",
    "### Data Imputation and Scaling\n",
    "Missing data imputation for a Township-Range is performed only using the existing data of that Township-Range (not the data of all Township-Ranges). For example:\n",
    "* a *fill forward* approach is used for many fields like crops, vegetation and soils. The percentage of land use per crop in 2014 in a Township-Range is imputed into the missing year 2015 for that particular Township-Range.\n",
    "* for fields like `PCT_OF_CAPACITY` (the capacity percentage of water reservoir), missing values in a Township-Range are filled using the min, mean, median or max values of that particular Township-Range. In this case the *fit* method of our custom impute pipeline does nothing. Not only the impute pipeline does not need to learn values from other Township-Ranges data points to impute missing values in a Township-Range, if it does it will not be able to impute data in the test set as we impute by Township-Range and the Township-Ranges in the test set are not seen when *fitting* the impute pipeline. The *transform* method, then simply fills the missing values in a Township-Range based on past values of that Township range. This way, we can split the train and test sets by Township-Range and impute missing value without any data leakage as the impute pipeline does not learn anything from the Township-Ranges in the test set.\n",
    "\n",
    "We use a MinMax scaler to scale all values between 0 and 1 for the neural network, except for the vegetation, soils and crops datasets which are already scaled between 0 and 1.\n",
    "\n",
    "It should be noted that we do not need to do any data imputation on the training and test sets *y* target feature since it does not have any missing data point."
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00005-bfcadfef-a8db-49d0-b935-b119372afd45",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 1651.828125
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00006-7869daf3-5d23-438c-adb9-3856df68ecbc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "28145966",
    "execution_start": 1663514018574,
    "execution_millis": 783,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 488
   },
   "source": [
    "test_size=0.15\n",
    "target_variable=\"GSE_GWE\"\n",
    "# Load the data from the ETL output files\n",
    "X = read_and_join_output_file()\n",
    "X.drop([\"SHORTAGE_COUNT\"], inplace=True, axis=1)\n",
    "# Split the input pandas Dataframe into training and test datasets, applies the impute pipeline\n",
    "# transformation and reshapes the datasets to 3D (samples, time, features) numpy arrays\n",
    "X_train, X_test, y_train, y_test, impute_pipeline, impute_columns, target_scaler = get_train_test_datasets(X, target_variable=target_variable, test_size=test_size, random_seed=RANDOM_SEED, save_to_file=True)\n",
    "model_predictions_df = pd.DataFrame(y_test, columns=[target_variable])\n",
    "model_scores_df = pd.DataFrame(columns=[\"MAE\", \"MSE\", \"RMSE\"])\n",
    "nb_features = X_train.shape[-1]\n",
    "get_sets_shapes(X_train, X_test)"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "                  nb_items  nb_timestamps  nb_features\ntraining dataset       406              7           80\ntest dataset            72              7           80",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nb_items</th>\n      <th>nb_timestamps</th>\n      <th>nb_features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>training dataset</th>\n      <td>406</td>\n      <td>7</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>test dataset</th>\n      <td>72</td>\n      <td>7</td>\n      <td>80</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00007-37992655-66f5-40e3-b123-60f647b6b035",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d53e1c9f",
    "execution_start": 1663514019360,
    "execution_millis": 1103,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 249.390625,
    "deepnote_output_heights": [
     139.390625
    ]
   },
   "source": [
    "set_config(display=\"diagram\")\n",
    "display(impute_pipeline)"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('columntransformer',\n                 ColumnTransformer(remainder=MinMaxScaler(),\n                                   transformers=[('wcr',\n                                                  Pipeline(steps=[('imputer',\n                                                                   PandasSimpleImputer(fill_value=0,\n                                                                                       strategy='constant')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['TOTALDRILLDEPTH_AVG',\n                                                   'WELLYIELD_AVG',\n                                                   'STATICWATERLEVEL_AVG',\n                                                   'TOPOFPERFORATEDINTERVAL_AVG',\n                                                   'BOTTOMOFPERFORATEDINTERVAL_AVG',\n                                                   'TOTALCOMPLETE...\n                                                                   GroupImputer(aggregation_func='min',\n                                                                                group_by_cols=['TOWNSHIP_RANGE'],\n                                                                                impute_for_col='PCT_OF_CAPACITY')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['PCT_OF_CAPACITY']),\n                                                 ('gse',\n                                                  Pipeline(steps=[('imputer',\n                                                                   GroupImputer(aggregation_func='median',\n                                                                                group_by_cols=['TOWNSHIP_RANGE'],\n                                                                                impute_for_col='GROUNDSURFACEELEVATION_AVG')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['GROUNDSURFACEELEVATION_AVG'])]))])",
      "text/html": "<style>#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a {color: black;background-color: white;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a pre{padding: 0;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-toggleable {background-color: white;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-estimator:hover {background-color: #d4ebff;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-item {z-index: 1;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-parallel-item:only-child::after {width: 0;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-3cf22b5e-4487-460f-a751-cbe37bfcfb1a\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7c264616-09b7-4bfb-93fb-015dd7ff7f1e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7c264616-09b7-4bfb-93fb-015dd7ff7f1e\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('columntransformer',\n                 ColumnTransformer(remainder=MinMaxScaler(),\n                                   transformers=[('wcr',\n                                                  Pipeline(steps=[('imputer',\n                                                                   PandasSimpleImputer(fill_value=0,\n                                                                                       strategy='constant')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['TOTALDRILLDEPTH_AVG',\n                                                   'WELLYIELD_AVG',\n                                                   'STATICWATERLEVEL_AVG',\n                                                   'TOPOFPERFORATEDINTERVAL_AVG',\n                                                   'BOTTOMOFPERFORATEDINTERVAL_AVG',\n                                                   'TOTALCOMPLETE...\n                                                                   GroupImputer(aggregation_func='min',\n                                                                                group_by_cols=['TOWNSHIP_RANGE'],\n                                                                                impute_for_col='PCT_OF_CAPACITY')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['PCT_OF_CAPACITY']),\n                                                 ('gse',\n                                                  Pipeline(steps=[('imputer',\n                                                                   GroupImputer(aggregation_func='median',\n                                                                                group_by_cols=['TOWNSHIP_RANGE'],\n                                                                                impute_for_col='GROUNDSURFACEELEVATION_AVG')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['GROUNDSURFACEELEVATION_AVG'])]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d8e40892-e956-48a7-b368-08f63320f0d4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d8e40892-e956-48a7-b368-08f63320f0d4\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=MinMaxScaler(),\n                  transformers=[('wcr',\n                                 Pipeline(steps=[('imputer',\n                                                  PandasSimpleImputer(fill_value=0,\n                                                                      strategy='constant')),\n                                                 ('scaler', MinMaxScaler())]),\n                                 ['TOTALDRILLDEPTH_AVG', 'WELLYIELD_AVG',\n                                  'STATICWATERLEVEL_AVG',\n                                  'TOPOFPERFORATEDINTERVAL_AVG',\n                                  'BOTTOMOFPERFORATEDINTERVAL_AVG',\n                                  'TOTALCOMPLETEDDEPTH_AVG']),\n                                ('veg_soils_crops',\n                                 Pipe...\n                                                  GroupImputer(aggregation_func='min',\n                                                               group_by_cols=['TOWNSHIP_RANGE'],\n                                                               impute_for_col='PCT_OF_CAPACITY')),\n                                                 ('scaler', MinMaxScaler())]),\n                                 ['PCT_OF_CAPACITY']),\n                                ('gse',\n                                 Pipeline(steps=[('imputer',\n                                                  GroupImputer(aggregation_func='median',\n                                                               group_by_cols=['TOWNSHIP_RANGE'],\n                                                               impute_for_col='GROUNDSURFACEELEVATION_AVG')),\n                                                 ('scaler', MinMaxScaler())]),\n                                 ['GROUNDSURFACEELEVATION_AVG'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e5cdb0ff-c375-4c73-84de-539371c8f0ec\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e5cdb0ff-c375-4c73-84de-539371c8f0ec\">wcr</label><div class=\"sk-toggleable__content\"><pre>['TOTALDRILLDEPTH_AVG', 'WELLYIELD_AVG', 'STATICWATERLEVEL_AVG', 'TOPOFPERFORATEDINTERVAL_AVG', 'BOTTOMOFPERFORATEDINTERVAL_AVG', 'TOTALCOMPLETEDDEPTH_AVG']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1fbc184d-78b2-454e-8a32-fb7fbbbddb0c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1fbc184d-78b2-454e-8a32-fb7fbbbddb0c\">PandasSimpleImputer</label><div class=\"sk-toggleable__content\"><pre>PandasSimpleImputer(fill_value=0, strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8ad4e877-57b8-4951-a04e-c02a228729ea\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8ad4e877-57b8-4951-a04e-c02a228729ea\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"596b8d6e-2745-4674-b335-380119c8a88d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"596b8d6e-2745-4674-b335-380119c8a88d\">veg_soils_crops</label><div class=\"sk-toggleable__content\"><pre>['VEGETATION_BLUE_OAK-GRAY_PINE', 'VEGETATION_CALIFORNIA_COAST_LIVE_OAK', 'VEGETATION_CANYON_LIVE_OAK', 'VEGETATION_HARD_CHAPARRAL', 'VEGETATION_KNOBCONE_PINE', 'VEGETATION_NON-NATIVE_HARDWOOD_FOREST', 'VEGETATION_PINYON-JUNIPER', 'SOIL_ALFISOLS_B', 'SOIL_ALFISOLS_C', 'SOIL_ALFISOLS_D', 'SOIL_ARIDISOLS_B', 'SOIL_ARIDISOLS_C', 'SOIL_ARIDISOLS_D', 'SOIL_ENTISOLS_A', 'SOIL_ENTISOLS_B', 'SOIL_ENTISOLS_C', 'SOIL_ENTISOLS_D', 'SOIL_HISTOSOLS_C', 'SOIL_INCEPTISOLS_B', 'SOIL_INCEPTISOLS_D', 'SOIL_MOLLISOLS_B', 'SOIL_MOLLISOLS_C', 'SOIL_MOLLISOLS_D', 'SOIL_ROCK_OUTCROP_D', 'SOIL_VERTISOLS_D', 'SOIL_WATER_', 'CROP_C', 'CROP_C6', 'CROP_D10', 'CROP_D12', 'CROP_D13', 'CROP_D14', 'CROP_D15', 'CROP_D16', 'CROP_D3', 'CROP_D5', 'CROP_D6', 'CROP_F1', 'CROP_F10', 'CROP_F16', 'CROP_F2', 'CROP_G', 'CROP_G2', 'CROP_G6', 'CROP_I', 'CROP_P1', 'CROP_P3', 'CROP_P6', 'CROP_R', 'CROP_R1', 'CROP_T10', 'CROP_T15', 'CROP_T18', 'CROP_T19', 'CROP_T21', 'CROP_T26', 'CROP_T30', 'CROP_T31', 'CROP_T4', 'CROP_T6', 'CROP_T8', 'CROP_T9', 'CROP_V', 'CROP_V3', 'CROP_YP']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"684b2597-6566-4db9-a2ec-63c9333bea71\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"684b2597-6566-4db9-a2ec-63c9333bea71\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function fill_from_prev_year at 0x000002161368C4C0>)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"fbd67982-e432-4929-8f6b-d14119eca14a\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"fbd67982-e432-4929-8f6b-d14119eca14a\">pop</label><div class=\"sk-toggleable__content\"><pre>['POPULATION_DENSITY']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d68fe1cd-cca2-4ec6-bd6e-869e16ed9ca9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d68fe1cd-cca2-4ec6-bd6e-869e16ed9ca9\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function fill_pop_from_prev_year at 0x000002161368C550>)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"418e49dc-a734-45b7-a5bc-e8be662c2dbc\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"418e49dc-a734-45b7-a5bc-e8be662c2dbc\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0fcdccf3-c545-4e19-a50e-9f6e7af554ef\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0fcdccf3-c545-4e19-a50e-9f6e7af554ef\">pct_capacity</label><div class=\"sk-toggleable__content\"><pre>['PCT_OF_CAPACITY']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"bae8fce3-0dac-4224-aa48-da0787f4c64f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"bae8fce3-0dac-4224-aa48-da0787f4c64f\">GroupImputer</label><div class=\"sk-toggleable__content\"><pre>GroupImputer(aggregation_func='min', group_by_cols=['TOWNSHIP_RANGE'],\n             impute_for_col='PCT_OF_CAPACITY')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"82f868a6-b667-4463-b247-01ffd6e3ca6c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"82f868a6-b667-4463-b247-01ffd6e3ca6c\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e362886c-7598-4f24-9a5f-6296f32cfba8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e362886c-7598-4f24-9a5f-6296f32cfba8\">gse</label><div class=\"sk-toggleable__content\"><pre>['GROUNDSURFACEELEVATION_AVG']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6ffeb1fc-879c-4997-aba2-ce5527d606fe\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"6ffeb1fc-879c-4997-aba2-ce5527d606fe\">GroupImputer</label><div class=\"sk-toggleable__content\"><pre>GroupImputer(aggregation_func='median', group_by_cols=['TOWNSHIP_RANGE'],\n             impute_for_col='GROUNDSURFACEELEVATION_AVG')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"175badf8-8722-455f-97c4-987fab4a5880\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"175badf8-8722-455f-97c4-987fab4a5880\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"fe00f779-8e6d-4b44-873d-2b599c7bd2f1\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"fe00f779-8e6d-4b44-873d-2b599c7bd2f1\">remainder</label><div class=\"sk-toggleable__content\"><pre>['AVERAGE_YEARLY_PRECIPITATION', 'GSE_GWE', 'WELL_COUNT_AGRICULTURE', 'WELL_COUNT_DOMESTIC', 'WELL_COUNT_INDUSTRIAL', 'WELL_COUNT_PUBLIC']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"10faad16-e119-46ed-930f-02d165854146\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"10faad16-e119-46ed-930f-02d165854146\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Different Models\n",
    "We tried 3 different LSTM models:\n",
    "* A simple model made of a single *LSTM* layer and an output *Dense* layer\n",
    "* A model made of a *LSTM* layer followed by a *Dense* and *Dropout* layers before the output layer\n",
    "* An Encoder-Decoder model made of 2 *LSTM* layers followed by a *Dense* and *Dropout* layers\n",
    "\n",
    "![LSTM Model Architectures](../doc/images/lstm_architectures.jpg)\n",
    "\n",
    "\n",
    "Encoder-decoder architectures are more common for sequence-to-sequence learning e.g., when forecasting the next 3 days (output sequence of length 3) based on the past year data (input sequence of length 365). In our case we only predict data for 1 time step in the feature. The output sequence being of length 1 this architecture might seem superfluous but has been tested anyway. This architecture was inspired by the Encoder-Decoder architecture in this article: *[CNN-LSTM-Based Models for Multiple Parallel Input and Multi-Step Forecast](https://towardsdatascience.com/cnn-lstm-based-models-for-multiple-parallel-input-and-multi-step-forecast-6fe2172f7668)*.\n",
    "\n",
    "As such models are made for sequence to sequence learning and forecasting, the output of such a model is different from the previous ones. It has an output of size *[samples, forecasting sequence length, target features]*. In our case the forecasting sequence length and number of target features are both 1.\n",
    "### Training Model 1 - Simple LSTM Model"
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00008-8dbefa1f-97eb-49d2-8b5b-0723848dec3b",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 1215.984375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00009-a4225230-65d3-4f60-9f3f-8a943a85fdf2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "572e554a",
    "execution_start": 1663514019514,
    "execution_millis": 962,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 614.8125
   },
   "source": [
    "m1_hyper_parameters = {\n",
    "    \"lstm_units\": 160,\n",
    "    \"lstm_activation\": \"sigmoid\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"validation_split\": 0.1,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 270,\n",
    "}\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(m1_hyper_parameters[\"lstm_units\"], activation=m1_hyper_parameters[\"lstm_activation\"], input_shape=(7, nb_features)))\n",
    "model1.add(Dense(1, activation=\"linear\"))\n",
    "model1.summary()"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 160)               154240    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,401\n",
      "Trainable params: 154,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00010-e719ffb9-4344-42b5-9ec9-6f4411fddf28",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4b5f6b50",
    "execution_start": 1663514019685,
    "execution_millis": 83438,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 863
   },
   "source": [
    "model1.compile(loss=\"mse\", optimizer=Adam(learning_rate=m1_hyper_parameters[\"learning_rate\"]), metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "model1.fit(X_train, y_train,\n",
    "           validation_split=m1_hyper_parameters[\"validation_split\"],\n",
    "           batch_size=m1_hyper_parameters[\"batch_size\"],\n",
    "           epochs=m1_hyper_parameters[\"epochs\"],\n",
    "           shuffle=True)\n",
    "yhat = model1.predict(X_test, verbose=0)\n",
    "yhat_inverse = target_scaler.inverse_transform(yhat)\n",
    "model_predictions_df[\"model_1_prediction\"] = yhat_inverse\n",
    "model_scores_df.loc[\"model 1\"] = evaluate_forecast(y_test, yhat_inverse)"
   ],
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "3/3 [==============================] - 1s 145ms/step - loss: 0.1126 - root_mean_squared_error: 0.3356 - val_loss: 0.1363 - val_root_mean_squared_error: 0.3691\n",
      "Epoch 2/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0869 - root_mean_squared_error: 0.2948 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1637\n",
      "Epoch 3/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0564 - root_mean_squared_error: 0.2375 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1988\n",
      "Epoch 4/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0579 - root_mean_squared_error: 0.2407 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1662\n",
      "Epoch 5/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0430 - root_mean_squared_error: 0.2073 - val_loss: 0.0567 - val_root_mean_squared_error: 0.2380\n",
      "Epoch 6/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0465 - root_mean_squared_error: 0.2156 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1751\n",
      "Epoch 7/270\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0357 - root_mean_squared_error: 0.1890 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1640\n",
      "Epoch 8/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0387 - root_mean_squared_error: 0.1966 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 9/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0300 - root_mean_squared_error: 0.1733 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1774\n",
      "Epoch 10/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0310 - root_mean_squared_error: 0.1759 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1731\n",
      "Epoch 11/270\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1559\n",
      "Epoch 12/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0267 - root_mean_squared_error: 0.1635 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1553\n",
      "Epoch 13/270\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 14/270\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0242 - root_mean_squared_error: 0.1556 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1606\n",
      "Epoch 15/270\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0234 - root_mean_squared_error: 0.1531 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 16/270\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0224 - root_mean_squared_error: 0.1498 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 17/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0218 - root_mean_squared_error: 0.1476 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "Epoch 18/270\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0209 - root_mean_squared_error: 0.1446 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 19/270\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1502\n",
      "Epoch 20/270\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1493\n",
      "Epoch 21/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0190 - root_mean_squared_error: 0.1377 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 22/270\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0185 - root_mean_squared_error: 0.1361 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1473\n",
      "Epoch 23/270\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0179 - root_mean_squared_error: 0.1340 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1461\n",
      "Epoch 24/270\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0176 - root_mean_squared_error: 0.1325 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 25/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 26/270\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 27/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0162 - root_mean_squared_error: 0.1275 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 28/270\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0157 - root_mean_squared_error: 0.1254 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1403\n",
      "Epoch 29/270\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 30/270\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0150 - root_mean_squared_error: 0.1223 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 31/270\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0147 - root_mean_squared_error: 0.1211 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1371\n",
      "Epoch 32/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0142 - root_mean_squared_error: 0.1192 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1361\n",
      "Epoch 33/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0139 - root_mean_squared_error: 0.1178 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1356\n",
      "Epoch 34/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0136 - root_mean_squared_error: 0.1164 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1341\n",
      "Epoch 35/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0133 - root_mean_squared_error: 0.1154 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1328\n",
      "Epoch 36/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0131 - root_mean_squared_error: 0.1145 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1335\n",
      "Epoch 37/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0125 - root_mean_squared_error: 0.1120 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 38/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0126 - root_mean_squared_error: 0.1123 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1299\n",
      "Epoch 39/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0122 - root_mean_squared_error: 0.1105 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 40/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 41/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0116 - root_mean_squared_error: 0.1075 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315\n",
      "Epoch 42/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 43/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0110 - root_mean_squared_error: 0.1049 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 44/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0108 - root_mean_squared_error: 0.1037 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1282\n",
      "Epoch 45/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0105 - root_mean_squared_error: 0.1023 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232\n",
      "Epoch 46/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0102 - root_mean_squared_error: 0.1010 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 47/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0100 - root_mean_squared_error: 0.1001 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 48/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0098 - root_mean_squared_error: 0.0991 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 49/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0095 - root_mean_squared_error: 0.0975 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 50/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0093 - root_mean_squared_error: 0.0964 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1202\n",
      "Epoch 51/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0091 - root_mean_squared_error: 0.0954 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 52/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0089 - root_mean_squared_error: 0.0943 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 53/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0089 - root_mean_squared_error: 0.0942 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 54/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 55/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0085 - root_mean_squared_error: 0.0921 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 56/270\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213\n",
      "Epoch 57/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0079 - root_mean_squared_error: 0.0887 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1158\n",
      "Epoch 58/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0077 - root_mean_squared_error: 0.0880 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 59/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0075 - root_mean_squared_error: 0.0868 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 60/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 61/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0073 - root_mean_squared_error: 0.0852 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1136\n",
      "Epoch 62/270\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0070 - root_mean_squared_error: 0.0835 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 63/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0069 - root_mean_squared_error: 0.0834 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 64/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 65/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0066 - root_mean_squared_error: 0.0810 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 66/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 67/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 68/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 69/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 70/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 71/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 72/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 73/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0055 - root_mean_squared_error: 0.0744 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 74/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 75/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 76/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 77/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 78/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 79/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0050 - root_mean_squared_error: 0.0706 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 80/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 81/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0048 - root_mean_squared_error: 0.0691 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 82/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0049 - root_mean_squared_error: 0.0697 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 83/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0047 - root_mean_squared_error: 0.0684 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 84/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0046 - root_mean_squared_error: 0.0679 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 85/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0047 - root_mean_squared_error: 0.0689 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 86/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0045 - root_mean_squared_error: 0.0672 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 87/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0044 - root_mean_squared_error: 0.0661 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 88/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0044 - root_mean_squared_error: 0.0664 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 89/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0044 - root_mean_squared_error: 0.0660 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 90/270\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0042 - root_mean_squared_error: 0.0648 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 91/270\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 92/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 93/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 94/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0040 - root_mean_squared_error: 0.0633 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 95/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0041 - root_mean_squared_error: 0.0636 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 96/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0040 - root_mean_squared_error: 0.0630 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 97/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0038 - root_mean_squared_error: 0.0618 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 98/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0037 - root_mean_squared_error: 0.0612 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 99/270\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0037 - root_mean_squared_error: 0.0609 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 100/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0037 - root_mean_squared_error: 0.0607 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 101/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0037 - root_mean_squared_error: 0.0606 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 102/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0037 - root_mean_squared_error: 0.0612 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 103/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0039 - root_mean_squared_error: 0.0628 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 104/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0038 - root_mean_squared_error: 0.0617 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 105/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0041 - root_mean_squared_error: 0.0644 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 106/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0043 - root_mean_squared_error: 0.0659 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 107/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0040 - root_mean_squared_error: 0.0630 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 108/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0037 - root_mean_squared_error: 0.0609 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 109/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0040 - root_mean_squared_error: 0.0629 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 110/270\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0038 - root_mean_squared_error: 0.0615 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 111/270\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0035 - root_mean_squared_error: 0.0593 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 112/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0035 - root_mean_squared_error: 0.0592 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 113/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 114/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 115/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0032 - root_mean_squared_error: 0.0569 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 116/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0032 - root_mean_squared_error: 0.0565 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 117/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0032 - root_mean_squared_error: 0.0569 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 118/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0033 - root_mean_squared_error: 0.0577 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 119/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0032 - root_mean_squared_error: 0.0569 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 120/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0032 - root_mean_squared_error: 0.0569 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 121/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0032 - root_mean_squared_error: 0.0563 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 122/270\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0034 - root_mean_squared_error: 0.0580 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 123/270\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0038 - root_mean_squared_error: 0.0619 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 124/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0032 - root_mean_squared_error: 0.0562 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 125/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - root_mean_squared_error: 0.0559 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 126/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - root_mean_squared_error: 0.0558 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 127/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0030 - root_mean_squared_error: 0.0550 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 128/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0031 - root_mean_squared_error: 0.0560 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 129/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - root_mean_squared_error: 0.0553 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 130/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - root_mean_squared_error: 0.0560 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 131/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0030 - root_mean_squared_error: 0.0545 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 132/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0030 - root_mean_squared_error: 0.0545 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 133/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0029 - root_mean_squared_error: 0.0542 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 134/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0029 - root_mean_squared_error: 0.0541 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 135/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0029 - root_mean_squared_error: 0.0543 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 136/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0034 - root_mean_squared_error: 0.0580 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 137/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0032 - root_mean_squared_error: 0.0567 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 138/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0029 - root_mean_squared_error: 0.0541 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 139/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 140/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 141/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0028 - root_mean_squared_error: 0.0534 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 142/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0028 - root_mean_squared_error: 0.0533 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 143/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 144/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0029 - root_mean_squared_error: 0.0534 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 145/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0030 - root_mean_squared_error: 0.0543 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 146/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0030 - root_mean_squared_error: 0.0550 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 147/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 148/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0033 - root_mean_squared_error: 0.0574 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 149/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0035 - root_mean_squared_error: 0.0590 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0875\n",
      "Epoch 150/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0032 - root_mean_squared_error: 0.0564 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 151/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - root_mean_squared_error: 0.0559 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 152/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0030 - root_mean_squared_error: 0.0549 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 153/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0029 - root_mean_squared_error: 0.0537 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 154/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0028 - root_mean_squared_error: 0.0528 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 155/270\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0028 - root_mean_squared_error: 0.0525 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 156/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0027 - root_mean_squared_error: 0.0524 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 157/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0028 - root_mean_squared_error: 0.0526 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 158/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0029 - root_mean_squared_error: 0.0534 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 159/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0029 - root_mean_squared_error: 0.0541 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 160/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0028 - root_mean_squared_error: 0.0531 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 161/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0029 - root_mean_squared_error: 0.0542 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 162/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0034 - root_mean_squared_error: 0.0579 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 163/270\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0028 - root_mean_squared_error: 0.0528 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 164/270\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0028 - root_mean_squared_error: 0.0525 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 165/270\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0028 - root_mean_squared_error: 0.0526 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 166/270\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0029 - root_mean_squared_error: 0.0538 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 167/270\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0029 - root_mean_squared_error: 0.0539 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 168/270\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0030 - root_mean_squared_error: 0.0544 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 169/270\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0030 - root_mean_squared_error: 0.0546 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800\n",
      "Epoch 170/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0030 - root_mean_squared_error: 0.0550 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 171/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0028 - root_mean_squared_error: 0.0531 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 172/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 173/270\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0027 - root_mean_squared_error: 0.0524 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 174/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0028 - root_mean_squared_error: 0.0531 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 175/270\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0033 - root_mean_squared_error: 0.0578 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 176/270\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0032 - root_mean_squared_error: 0.0567 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 177/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0032 - root_mean_squared_error: 0.0570 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 178/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0030 - root_mean_squared_error: 0.0551 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 179/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0032 - root_mean_squared_error: 0.0564 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 180/270\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0027 - root_mean_squared_error: 0.0519 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 181/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0027 - root_mean_squared_error: 0.0521 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 182/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0027 - root_mean_squared_error: 0.0523 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 183/270\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0027 - root_mean_squared_error: 0.0518 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 184/270\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0029 - root_mean_squared_error: 0.0540 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 185/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0028 - root_mean_squared_error: 0.0533 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 186/270\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0029 - root_mean_squared_error: 0.0539 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 187/270\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0030 - root_mean_squared_error: 0.0546 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 188/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0027 - root_mean_squared_error: 0.0522 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 189/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0028 - root_mean_squared_error: 0.0533 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 190/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0028 - root_mean_squared_error: 0.0526 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 191/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0030 - root_mean_squared_error: 0.0547 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 192/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0027 - root_mean_squared_error: 0.0522 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 193/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0029 - root_mean_squared_error: 0.0534 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 194/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0028 - root_mean_squared_error: 0.0532 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 195/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0027 - root_mean_squared_error: 0.0522 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 196/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0027 - root_mean_squared_error: 0.0520 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 197/270\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0028 - root_mean_squared_error: 0.0524 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 198/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0028 - root_mean_squared_error: 0.0529 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 199/270\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0028 - root_mean_squared_error: 0.0529 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 200/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0027 - root_mean_squared_error: 0.0524 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 201/270\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0027 - root_mean_squared_error: 0.0521 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786\n",
      "Epoch 202/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 203/270\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0028 - root_mean_squared_error: 0.0525 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 204/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0026 - root_mean_squared_error: 0.0512 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789\n",
      "Epoch 205/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0028 - root_mean_squared_error: 0.0532 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 206/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0031 - root_mean_squared_error: 0.0554 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 207/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0027 - root_mean_squared_error: 0.0518 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788\n",
      "Epoch 208/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0028 - root_mean_squared_error: 0.0526 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 209/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0027 - root_mean_squared_error: 0.0523 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796\n",
      "Epoch 210/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0029 - root_mean_squared_error: 0.0543 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 211/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - root_mean_squared_error: 0.0559 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 212/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0027 - root_mean_squared_error: 0.0518 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 213/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - root_mean_squared_error: 0.0560 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 214/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0033 - root_mean_squared_error: 0.0573 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0765\n",
      "Epoch 215/270\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0039 - root_mean_squared_error: 0.0627 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 216/270\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0032 - root_mean_squared_error: 0.0570 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 217/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0035 - root_mean_squared_error: 0.0592 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 218/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0031 - root_mean_squared_error: 0.0561 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772\n",
      "Epoch 219/270\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0041 - root_mean_squared_error: 0.0642 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 220/270\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 221/270\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0036 - root_mean_squared_error: 0.0602 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761\n",
      "Epoch 222/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0033 - root_mean_squared_error: 0.0571 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 223/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 224/270\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0028 - root_mean_squared_error: 0.0529 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 225/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0028 - root_mean_squared_error: 0.0534 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 226/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0028 - root_mean_squared_error: 0.0530 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 227/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0032 - root_mean_squared_error: 0.0570 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 228/270\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0029 - root_mean_squared_error: 0.0543 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796\n",
      "Epoch 229/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0028 - root_mean_squared_error: 0.0526 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 230/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 231/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0026 - root_mean_squared_error: 0.0511 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854\n",
      "Epoch 232/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0026 - root_mean_squared_error: 0.0513 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 233/270\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0026 - root_mean_squared_error: 0.0511 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 234/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0027 - root_mean_squared_error: 0.0515 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0830\n",
      "Epoch 235/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0026 - root_mean_squared_error: 0.0512 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789\n",
      "Epoch 236/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0028 - root_mean_squared_error: 0.0530 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787\n",
      "Epoch 237/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0027 - root_mean_squared_error: 0.0516 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 238/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0031 - root_mean_squared_error: 0.0553 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796\n",
      "Epoch 239/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0028 - root_mean_squared_error: 0.0527 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 240/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0028 - root_mean_squared_error: 0.0527 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 241/270\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0026 - root_mean_squared_error: 0.0514 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 242/270\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0027 - root_mean_squared_error: 0.0523 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 243/270\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0030 - root_mean_squared_error: 0.0551 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0769\n",
      "Epoch 244/270\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0029 - root_mean_squared_error: 0.0537 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 245/270\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0027 - root_mean_squared_error: 0.0515 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0875\n",
      "Epoch 246/270\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0026 - root_mean_squared_error: 0.0514 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 247/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0029 - root_mean_squared_error: 0.0536 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 248/270\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0026 - root_mean_squared_error: 0.0515 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 249/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0030 - root_mean_squared_error: 0.0552 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 250/270\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0031 - root_mean_squared_error: 0.0556 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 251/270\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0031 - root_mean_squared_error: 0.0554 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 252/270\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0029 - root_mean_squared_error: 0.0538 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 253/270\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0028 - root_mean_squared_error: 0.0528 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751\n",
      "Epoch 254/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0033 - root_mean_squared_error: 0.0576 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 255/270\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0026 - root_mean_squared_error: 0.0513 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 256/270\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0027 - root_mean_squared_error: 0.0524 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854\n",
      "Epoch 257/270\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0026 - root_mean_squared_error: 0.0514 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 258/270\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0027 - root_mean_squared_error: 0.0516 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 259/270\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0026 - root_mean_squared_error: 0.0506 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 260/270\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0026 - root_mean_squared_error: 0.0514 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 261/270\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0028 - root_mean_squared_error: 0.0533 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761\n",
      "Epoch 262/270\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0030 - root_mean_squared_error: 0.0544 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 263/270\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0028 - root_mean_squared_error: 0.0527 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 264/270\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0027 - root_mean_squared_error: 0.0517 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 265/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0026 - root_mean_squared_error: 0.0508 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 266/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0026 - root_mean_squared_error: 0.0508 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 267/270\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0027 - root_mean_squared_error: 0.0521 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 268/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0033 - root_mean_squared_error: 0.0573 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 269/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0029 - root_mean_squared_error: 0.0542 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 270/270\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0027 - root_mean_squared_error: 0.0521 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Model 2 - LSTM + Dense Layer Model"
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00011-e6b1dd65-7776-46ca-8edc-082f8ffeeb5a",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00012-783999f3-4a70-4d8d-80df-10b51c0144a5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bea59a1b",
    "execution_start": 1663514103123,
    "execution_millis": 111,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 741.1875
   },
   "source": [
    "m2_hyper_parameters = {\n",
    "    \"lstm_units\": 100,\n",
    "    \"lstm_activation\": \"sigmoid\",\n",
    "    \"dense_units\": 11,\n",
    "    \"dense_activation\": \"tanh\",\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"validation_split\": 0.1,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 200,\n",
    "}\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(m2_hyper_parameters[\"lstm_units\"], activation=m2_hyper_parameters[\"lstm_activation\"], input_shape=(7, nb_features)))\n",
    "model2.add(Dense(m2_hyper_parameters[\"dense_units\"], activation=m2_hyper_parameters[\"dense_activation\"]))\n",
    "model2.add(Dropout(m2_hyper_parameters[\"dropout\"]))\n",
    "model2.add(Dense(1, activation=\"linear\"))\n",
    "model2.summary()"
   ],
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 100)               72400     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 11)                1111      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 11)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,523\n",
      "Trainable params: 73,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00013-743dc426-12e6-4e71-b9cc-197f88604697",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "42ac0cf9",
    "execution_start": 1663514103234,
    "execution_millis": 50633,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 863
   },
   "source": [
    "model2.compile(loss=\"mse\", optimizer=Adam(learning_rate=m2_hyper_parameters[\"learning_rate\"]), metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "model2.fit(X_train, y_train,\n",
    "           validation_split=m2_hyper_parameters[\"validation_split\"],\n",
    "           batch_size=m2_hyper_parameters[\"batch_size\"],\n",
    "           epochs=m2_hyper_parameters[\"epochs\"],\n",
    "           shuffle=True)\n",
    "yhat = model2.predict(X_test, verbose=0)\n",
    "yhat_inverse = target_scaler.inverse_transform(yhat)\n",
    "model_predictions_df[\"model_2_prediction\"] = yhat_inverse\n",
    "model_scores_df.loc[\"model 2\"] = evaluate_forecast(y_test, yhat_inverse)"
   ],
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 1s 31ms/step - loss: 0.1479 - root_mean_squared_error: 0.3846 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1810\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1173 - root_mean_squared_error: 0.3425 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1031 - root_mean_squared_error: 0.3211 - val_loss: 0.0348 - val_root_mean_squared_error: 0.1866\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0970 - root_mean_squared_error: 0.3114 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1876\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1003 - root_mean_squared_error: 0.3166 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1815\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0891 - root_mean_squared_error: 0.2985 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1759\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0831 - root_mean_squared_error: 0.2883 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1710\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0730 - root_mean_squared_error: 0.2702 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1847\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0696 - root_mean_squared_error: 0.2638 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0673 - root_mean_squared_error: 0.2594 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1782\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0543 - root_mean_squared_error: 0.2330 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0541 - root_mean_squared_error: 0.2326 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1620\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0513 - root_mean_squared_error: 0.2265 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1712\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0490 - root_mean_squared_error: 0.2214 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1668\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0433 - root_mean_squared_error: 0.2081 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1632\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0381 - root_mean_squared_error: 0.1951 - val_loss: 0.0263 - val_root_mean_squared_error: 0.1621\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1640\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0371 - root_mean_squared_error: 0.1927 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1593\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0356 - root_mean_squared_error: 0.1888 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1589\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0347 - root_mean_squared_error: 0.1864 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0318 - root_mean_squared_error: 0.1783 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0295 - root_mean_squared_error: 0.1717 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0321 - root_mean_squared_error: 0.1792 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0288 - root_mean_squared_error: 0.1697 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0249 - root_mean_squared_error: 0.1578 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0257 - root_mean_squared_error: 0.1604 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0239 - root_mean_squared_error: 0.1546 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0256 - root_mean_squared_error: 0.1599 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1489\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0234 - root_mean_squared_error: 0.1530 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1489\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0236 - root_mean_squared_error: 0.1536 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1468\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0218 - root_mean_squared_error: 0.1477 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0215 - root_mean_squared_error: 0.1467 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1474\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0222 - root_mean_squared_error: 0.1489 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0214 - root_mean_squared_error: 0.1463 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1424\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0205 - root_mean_squared_error: 0.1433 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0204 - root_mean_squared_error: 0.1430 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1408\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0206 - root_mean_squared_error: 0.1435 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1403\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0191 - root_mean_squared_error: 0.1382 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0189 - root_mean_squared_error: 0.1374 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0200 - root_mean_squared_error: 0.1414 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0182 - root_mean_squared_error: 0.1350 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1383\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0182 - root_mean_squared_error: 0.1350 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1371\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1366\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0170 - root_mean_squared_error: 0.1302 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0167 - root_mean_squared_error: 0.1292 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1360\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0167 - root_mean_squared_error: 0.1291 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0182 - root_mean_squared_error: 0.1350 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1364\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0164 - root_mean_squared_error: 0.1282 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1329\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0163 - root_mean_squared_error: 0.1275 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1323\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0160 - root_mean_squared_error: 0.1265 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1318\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0154 - root_mean_squared_error: 0.1242 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0156 - root_mean_squared_error: 0.1251 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1337\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0150 - root_mean_squared_error: 0.1226 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0158 - root_mean_squared_error: 0.1256 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0158 - root_mean_squared_error: 0.1257 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0154 - root_mean_squared_error: 0.1239 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0150 - root_mean_squared_error: 0.1223 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1275\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0146 - root_mean_squared_error: 0.1210 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1282\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0147 - root_mean_squared_error: 0.1211 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0131 - root_mean_squared_error: 0.1143 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0135 - root_mean_squared_error: 0.1160 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0131 - root_mean_squared_error: 0.1142 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0131 - root_mean_squared_error: 0.1145 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0143 - root_mean_squared_error: 0.1197 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0136 - root_mean_squared_error: 0.1165 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0125 - root_mean_squared_error: 0.1116 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0116 - root_mean_squared_error: 0.1076 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0124 - root_mean_squared_error: 0.1112 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0120 - root_mean_squared_error: 0.1093 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0129 - root_mean_squared_error: 0.1134 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0126 - root_mean_squared_error: 0.1124 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0127 - root_mean_squared_error: 0.1127 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0115 - root_mean_squared_error: 0.1074 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0118 - root_mean_squared_error: 0.1086 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1209\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0124 - root_mean_squared_error: 0.1115 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0112 - root_mean_squared_error: 0.1061 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0106 - root_mean_squared_error: 0.1029 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0108 - root_mean_squared_error: 0.1037 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0116 - root_mean_squared_error: 0.1079 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0108 - root_mean_squared_error: 0.1038 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0112 - root_mean_squared_error: 0.1060 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0111 - root_mean_squared_error: 0.1054 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1218\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0103 - root_mean_squared_error: 0.1013 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0101 - root_mean_squared_error: 0.1007 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0102 - root_mean_squared_error: 0.1008 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0101 - root_mean_squared_error: 0.1007 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0095 - root_mean_squared_error: 0.0973 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0093 - root_mean_squared_error: 0.0964 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0097 - root_mean_squared_error: 0.0985 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0101 - root_mean_squared_error: 0.1003 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0100 - root_mean_squared_error: 0.1002 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1130\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0095 - root_mean_squared_error: 0.0974 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1145\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0099 - root_mean_squared_error: 0.0994 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0093 - root_mean_squared_error: 0.0962 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1149\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0089 - root_mean_squared_error: 0.0944 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0085 - root_mean_squared_error: 0.0922 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0088 - root_mean_squared_error: 0.0939 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0088 - root_mean_squared_error: 0.0938 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0082 - root_mean_squared_error: 0.0907 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - root_mean_squared_error: 0.0898 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0087 - root_mean_squared_error: 0.0931 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0086 - root_mean_squared_error: 0.0925 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0076 - root_mean_squared_error: 0.0875 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0090 - root_mean_squared_error: 0.0949 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0085 - root_mean_squared_error: 0.0922 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0080 - root_mean_squared_error: 0.0892 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - root_mean_squared_error: 0.0902 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0080 - root_mean_squared_error: 0.0893 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0073 - root_mean_squared_error: 0.0854 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0070 - root_mean_squared_error: 0.0837 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0069 - root_mean_squared_error: 0.0833 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0073 - root_mean_squared_error: 0.0854 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0074 - root_mean_squared_error: 0.0861 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0077 - root_mean_squared_error: 0.0879 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0074 - root_mean_squared_error: 0.0862 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0066 - root_mean_squared_error: 0.0812 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0070 - root_mean_squared_error: 0.0840 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0075 - root_mean_squared_error: 0.0865 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0066 - root_mean_squared_error: 0.0815 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0066 - root_mean_squared_error: 0.0810 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0073 - root_mean_squared_error: 0.0852 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0069 - root_mean_squared_error: 0.0829 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0060 - root_mean_squared_error: 0.0777 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0074 - root_mean_squared_error: 0.0862 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0060 - root_mean_squared_error: 0.0774 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0070 - root_mean_squared_error: 0.0835 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0063 - root_mean_squared_error: 0.0797 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0064 - root_mean_squared_error: 0.0802 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0075 - root_mean_squared_error: 0.0865 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0065 - root_mean_squared_error: 0.0804 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0066 - root_mean_squared_error: 0.0811 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0059 - root_mean_squared_error: 0.0768 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0060 - root_mean_squared_error: 0.0775 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0060 - root_mean_squared_error: 0.0774 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0068 - root_mean_squared_error: 0.0826 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0060 - root_mean_squared_error: 0.0775 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0054 - root_mean_squared_error: 0.0738 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0054 - root_mean_squared_error: 0.0738 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0056 - root_mean_squared_error: 0.0746 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0058 - root_mean_squared_error: 0.0764 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0054 - root_mean_squared_error: 0.0737 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0064 - root_mean_squared_error: 0.0801 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0056 - root_mean_squared_error: 0.0746 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0058 - root_mean_squared_error: 0.0761 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0058 - root_mean_squared_error: 0.0761 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0050 - root_mean_squared_error: 0.0704 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0056 - root_mean_squared_error: 0.0746 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0047 - root_mean_squared_error: 0.0685 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0047 - root_mean_squared_error: 0.0685 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0049 - root_mean_squared_error: 0.0702 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0049 - root_mean_squared_error: 0.0700 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0048 - root_mean_squared_error: 0.0690 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0047 - root_mean_squared_error: 0.0689 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0055 - root_mean_squared_error: 0.0742 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0049 - root_mean_squared_error: 0.0697 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0045 - root_mean_squared_error: 0.0671 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0047 - root_mean_squared_error: 0.0682 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0043 - root_mean_squared_error: 0.0657 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0045 - root_mean_squared_error: 0.0670 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0049 - root_mean_squared_error: 0.0698 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0042 - root_mean_squared_error: 0.0650 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0046 - root_mean_squared_error: 0.0681 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0045 - root_mean_squared_error: 0.0673 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0043 - root_mean_squared_error: 0.0657 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0043 - root_mean_squared_error: 0.0659 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0043 - root_mean_squared_error: 0.0659 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Model 3 - Encoder-Decoder LSTM Model"
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00014-9cd3a6e9-50d1-4229-9ac9-c9fdc9b259ba",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00015-20135aa5-3f26-4c22-80b9-7e4f15db7b95",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4eda919f",
    "execution_start": 1663514153871,
    "execution_millis": 389,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 952.3125
   },
   "source": [
    "m3_hyper_parameters = {\n",
    "    \"lstm_units\": 300,\n",
    "    \"lstm_activation\": \"sigmoid\",\n",
    "    \"2nd_lstm_units\": 140,\n",
    "    \"2nd_lstm_activation\": \"sigmoid\",\n",
    "    \"dense_units\": 21,\n",
    "    \"dense_activation\": \"tanh\",\n",
    "    \"dropout\": 0.2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"validation_split\": 0.1,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 200,\n",
    "}\n",
    "\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(m3_hyper_parameters[\"lstm_units\"], activation=m3_hyper_parameters[\"lstm_activation\"], input_shape=(7, nb_features)))\n",
    "model3.add(RepeatVector(1))\n",
    "model3.add(LSTM(m3_hyper_parameters[\"2nd_lstm_units\"], activation=m3_hyper_parameters[\"lstm_activation\"], return_sequences=True))\n",
    "model3.add(TimeDistributed(Dense(m3_hyper_parameters[\"dense_units\"], activation=m3_hyper_parameters[\"dense_activation\"])))\n",
    "model3.add(Dropout(m3_hyper_parameters[\"dropout\"]))\n",
    "model3.add(Dense(1, activation=\"linear\"))\n",
    "model3.summary()"
   ],
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 300)               457200    \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 1, 300)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 1, 140)            246960    \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 1, 21)            2961      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 21)             0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1, 1)              22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 707,143\n",
      "Trainable params: 707,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00016-304bc0a1-68ca-49cc-a5de-eb6b891fe1c5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cf84507f",
    "execution_start": 1663514154303,
    "execution_millis": 139168,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 881
   },
   "source": [
    "y_train_3d =  y_train[..., np.newaxis]\n",
    "model3.compile(loss=\"mse\", optimizer=Adam(learning_rate=m3_hyper_parameters[\"learning_rate\"]), metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "model3.fit(X_train, y_train_3d,\n",
    "           validation_split=m3_hyper_parameters[\"validation_split\"],\n",
    "           batch_size=m3_hyper_parameters[\"batch_size\"],\n",
    "           epochs=m3_hyper_parameters[\"epochs\"],\n",
    "           shuffle=True)\n",
    "yhat = model3.predict(X_test, verbose=0)\n",
    "yhat_inverse = target_scaler.inverse_transform(yhat.squeeze(2))\n",
    "model_predictions_df[\"model_3_prediction\"] = yhat_inverse\n",
    "model_scores_df.loc[\"model 3\"] = evaluate_forecast(y_test, yhat_inverse)"
   ],
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 2s 64ms/step - loss: 0.1871 - root_mean_squared_error: 0.4325 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1583\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0834 - root_mean_squared_error: 0.2888 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1801\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0599 - root_mean_squared_error: 0.2448 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2065\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0446 - root_mean_squared_error: 0.2111 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1860\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0389 - root_mean_squared_error: 0.1971 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0405 - root_mean_squared_error: 0.2012 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1685\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0381 - root_mean_squared_error: 0.1951 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2401\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0409 - root_mean_squared_error: 0.2022 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0355 - root_mean_squared_error: 0.1885 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1558\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0374 - root_mean_squared_error: 0.1933 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0339 - root_mean_squared_error: 0.1840 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0282 - root_mean_squared_error: 0.1679 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1775\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0237 - root_mean_squared_error: 0.1538 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1515\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0226 - root_mean_squared_error: 0.1503 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1684\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0205 - root_mean_squared_error: 0.1433 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1468\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1456\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0183 - root_mean_squared_error: 0.1353 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1390\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0202 - root_mean_squared_error: 0.1421 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0143 - root_mean_squared_error: 0.1195 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1372\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0127 - root_mean_squared_error: 0.1129 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1366\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0143 - root_mean_squared_error: 0.1197 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0119 - root_mean_squared_error: 0.1093 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0098 - root_mean_squared_error: 0.0989 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0124 - root_mean_squared_error: 0.1112 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1152\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0126 - root_mean_squared_error: 0.1122 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0093 - root_mean_squared_error: 0.0965 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0086 - root_mean_squared_error: 0.0929 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0077 - root_mean_squared_error: 0.0875 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0090 - root_mean_squared_error: 0.0950 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0090 - root_mean_squared_error: 0.0948 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0108 - root_mean_squared_error: 0.1038 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1616\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0096 - root_mean_squared_error: 0.0977 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0081 - root_mean_squared_error: 0.0898 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0057 - root_mean_squared_error: 0.0756 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0057 - root_mean_squared_error: 0.0758 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0066 - root_mean_squared_error: 0.0814 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1333\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0067 - root_mean_squared_error: 0.0816 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0102 - root_mean_squared_error: 0.1012 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0091 - root_mean_squared_error: 0.0954 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0112 - root_mean_squared_error: 0.1060 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0067 - root_mean_squared_error: 0.0816 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0059 - root_mean_squared_error: 0.0770 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0059 - root_mean_squared_error: 0.0766 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0065 - root_mean_squared_error: 0.0805 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0102 - root_mean_squared_error: 0.1011 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0083 - root_mean_squared_error: 0.0914 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0067 - root_mean_squared_error: 0.0817 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0056 - root_mean_squared_error: 0.0750 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0061 - root_mean_squared_error: 0.0779 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0060 - root_mean_squared_error: 0.0777 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0073 - root_mean_squared_error: 0.0855 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0051 - root_mean_squared_error: 0.0715 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1362\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0066 - root_mean_squared_error: 0.0813 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0069 - root_mean_squared_error: 0.0831 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0877\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0075 - root_mean_squared_error: 0.0868 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0049 - root_mean_squared_error: 0.0701 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0044 - root_mean_squared_error: 0.0664 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0051 - root_mean_squared_error: 0.0711 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0062 - root_mean_squared_error: 0.0788 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0050 - root_mean_squared_error: 0.0709 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0058 - root_mean_squared_error: 0.0763 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0068 - root_mean_squared_error: 0.0823 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0045 - root_mean_squared_error: 0.0668 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0063 - root_mean_squared_error: 0.0791 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0050 - root_mean_squared_error: 0.0704 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0061 - root_mean_squared_error: 0.0778 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0044 - root_mean_squared_error: 0.0667 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0044 - root_mean_squared_error: 0.0666 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0044 - root_mean_squared_error: 0.0667 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1465\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0068 - root_mean_squared_error: 0.0827 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0975\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0059 - root_mean_squared_error: 0.0770 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0075 - root_mean_squared_error: 0.0869 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0041 - root_mean_squared_error: 0.0642 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1152\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0043 - root_mean_squared_error: 0.0653 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0039 - root_mean_squared_error: 0.0626 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0049 - root_mean_squared_error: 0.0702 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0046 - root_mean_squared_error: 0.0681 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0043 - root_mean_squared_error: 0.0658 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0044 - root_mean_squared_error: 0.0666 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0060 - root_mean_squared_error: 0.0774 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0038 - root_mean_squared_error: 0.0619 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1155\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0068 - root_mean_squared_error: 0.0825 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0055 - root_mean_squared_error: 0.0745 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0043 - root_mean_squared_error: 0.0654 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0037 - root_mean_squared_error: 0.0606 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0044 - root_mean_squared_error: 0.0664 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0048 - root_mean_squared_error: 0.0694 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1364\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0046 - root_mean_squared_error: 0.0682 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0046 - root_mean_squared_error: 0.0678 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0038 - root_mean_squared_error: 0.0612 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0049 - root_mean_squared_error: 0.0702 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0045 - root_mean_squared_error: 0.0671 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0069 - root_mean_squared_error: 0.0829 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0047 - root_mean_squared_error: 0.0685 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0043 - root_mean_squared_error: 0.0658 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0049 - root_mean_squared_error: 0.0700 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0048 - root_mean_squared_error: 0.0691 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0033 - root_mean_squared_error: 0.0574 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0049 - root_mean_squared_error: 0.0698 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0048 - root_mean_squared_error: 0.0694 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0041 - root_mean_squared_error: 0.0644 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0048 - root_mean_squared_error: 0.0692 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0043 - root_mean_squared_error: 0.0659 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0048 - root_mean_squared_error: 0.0691 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0039 - root_mean_squared_error: 0.0627 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0046 - root_mean_squared_error: 0.0675 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1343\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0066 - root_mean_squared_error: 0.0815 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0067 - root_mean_squared_error: 0.0818 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0045 - root_mean_squared_error: 0.0669 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0052 - root_mean_squared_error: 0.0724 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0040 - root_mean_squared_error: 0.0632 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0039 - root_mean_squared_error: 0.0621 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0047 - root_mean_squared_error: 0.0686 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0050 - root_mean_squared_error: 0.0709 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0039 - root_mean_squared_error: 0.0622 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0040 - root_mean_squared_error: 0.0629 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0043 - root_mean_squared_error: 0.0657 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0045 - root_mean_squared_error: 0.0673 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0054 - root_mean_squared_error: 0.0733 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0815\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0043 - root_mean_squared_error: 0.0652 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0047 - root_mean_squared_error: 0.0688 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0054 - root_mean_squared_error: 0.0738 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0046 - root_mean_squared_error: 0.0679 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1398\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0066 - root_mean_squared_error: 0.0812 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0042 - root_mean_squared_error: 0.0649 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0041 - root_mean_squared_error: 0.0638 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0048 - root_mean_squared_error: 0.0690 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0044 - root_mean_squared_error: 0.0660 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0046 - root_mean_squared_error: 0.0679 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0041 - root_mean_squared_error: 0.0640 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0045 - root_mean_squared_error: 0.0667 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0038 - root_mean_squared_error: 0.0616 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0033 - root_mean_squared_error: 0.0573 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0040 - root_mean_squared_error: 0.0636 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0815\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0054 - root_mean_squared_error: 0.0734 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0077 - root_mean_squared_error: 0.0877 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0044 - root_mean_squared_error: 0.0664 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0055 - root_mean_squared_error: 0.0744 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0049 - root_mean_squared_error: 0.0700 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0039 - root_mean_squared_error: 0.0625 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0050 - root_mean_squared_error: 0.0707 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0044 - root_mean_squared_error: 0.0661 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0036 - root_mean_squared_error: 0.0598 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0035 - root_mean_squared_error: 0.0592 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0040 - root_mean_squared_error: 0.0630 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparing the Different Models\n",
    "### Comparing the Model Scores"
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00017-9c7865d2-476b-4a26-90de-be34a071ed60",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 118
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00018-d8c65b52-4048-461d-aef6-520b46a190e1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "693c61b9",
    "execution_start": 1663514293473,
    "execution_millis": 21,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 308
   },
   "source": [
    "model_scores_df"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "               MAE          MSE       RMSE\nmodel 1  23.793732  1208.829956  34.768230\nmodel 2  30.339775  1814.698730  42.599281\nmodel 3  30.205767  1610.084839  40.125862",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>model 1</th>\n      <td>23.793732</td>\n      <td>1208.829956</td>\n      <td>34.768230</td>\n    </tr>\n    <tr>\n      <th>model 2</th>\n      <td>30.339775</td>\n      <td>1814.698730</td>\n      <td>42.599281</td>\n    </tr>\n    <tr>\n      <th>model 3</th>\n      <td>30.205767</td>\n      <td>1610.084839</td>\n      <td>40.125862</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparing the Model Predictions on the Test Dataset\n",
    "Here we are comparing the target variable values for the year 2021 for the Township-Ranges in the test set compared to the prediction made by each model based on the 2014-2020 data for the Township-Ranges in the test set."
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00019-8ef0db79-bb9b-4acc-a823-94f42f9fdfaf",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 122.78125
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00020-170ccca4-1d89-43af-9cae-b454aed41824",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9d40daa8",
    "execution_start": 1663514293494,
    "execution_millis": 69,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 595
   },
   "source": [
    "model_predictions_df"
   ],
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "       GSE_GWE  model_1_prediction  model_2_prediction  model_3_prediction\n0    33.198000           22.690382           27.054747            8.250940\n1    34.795000           50.077850           51.687843           31.764212\n2   161.756667           68.355354           67.346954           47.582420\n3    54.423000           40.084999           40.748684           21.895430\n4    80.653077           97.764793          102.518166           73.492050\n..         ...                 ...                 ...                 ...\n67  187.252308          178.960907          164.108978          167.784225\n68  179.551290          153.492096          163.449860          148.738907\n69  236.543750          249.778610          250.463730          243.026459\n70  292.550000          274.968384          248.172867          255.672699\n71  173.915909          170.234756          151.059586          148.342804\n\n[72 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GSE_GWE</th>\n      <th>model_1_prediction</th>\n      <th>model_2_prediction</th>\n      <th>model_3_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33.198000</td>\n      <td>22.690382</td>\n      <td>27.054747</td>\n      <td>8.250940</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34.795000</td>\n      <td>50.077850</td>\n      <td>51.687843</td>\n      <td>31.764212</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>161.756667</td>\n      <td>68.355354</td>\n      <td>67.346954</td>\n      <td>47.582420</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54.423000</td>\n      <td>40.084999</td>\n      <td>40.748684</td>\n      <td>21.895430</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>80.653077</td>\n      <td>97.764793</td>\n      <td>102.518166</td>\n      <td>73.492050</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>187.252308</td>\n      <td>178.960907</td>\n      <td>164.108978</td>\n      <td>167.784225</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>179.551290</td>\n      <td>153.492096</td>\n      <td>163.449860</td>\n      <td>148.738907</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>236.543750</td>\n      <td>249.778610</td>\n      <td>250.463730</td>\n      <td>243.026459</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>292.550000</td>\n      <td>274.968384</td>\n      <td>248.172867</td>\n      <td>255.672699</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>173.915909</td>\n      <td>170.234756</td>\n      <td>151.059586</td>\n      <td>148.342804</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows  4 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the model scores it turns out that the simplest of the three LSTM models is the one having the best scores.\n",
    "\n",
    "However, considering all the measurements between 2014 and 2022, the `GSE_GWE` (Ground Surface Elevation to Groundwater Water Elevation - Depth to groundwater elevation in feet below ground surface) target value has a\n",
    "* median of 137.09 (~41.7 meters)\n",
    "* mean value of 167.37 feet (~50.9 meters)\n",
    "* min value of 0.5 feet (0 meters)\n",
    "* max value of 727.5 feet (221.6 meters)\n",
    "\n",
    "A mean average error of 23.80 feet (7 meters), and root mean square error of 34.77 feet (10.4 meters) in the prediction is fairly large. Even the best model does not seem to be accurate enough to be useful.\n",
    "\n",
    "We save the best model anyway to perform predictions and analyze the results. Refer to the notebook `/ml/deeplearning_results.ipynb` for the analysis of the 2022 predictions results."
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00021-6b002d14-1702-4d6f-b828-8901cadadfb1",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 341.296875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00022-ab071fcd-f199-4609-a30e-c36d501cb8ae",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cf9d7c78",
    "execution_start": 1663514293561,
    "execution_millis": 1725,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 323.1875
   },
   "source": [
    "model_dir = \"../assets/models/\"\n",
    "keras_model_dir = os.path.join(model_dir, \"keras_lstm_model\")\n",
    "os.makedirs(keras_model_dir, exist_ok=True)\n",
    "# Save the Keras Model\n",
    "model1.save(keras_model_dir)\n",
    "# Save the data imputation pipeline and target min-max scaler\n",
    "pipeline_data = {\n",
    "    \"impute_pipeline\": impute_pipeline,\n",
    "    \"impute_columns\": impute_columns,\n",
    "    \"target_scaler\": target_scaler\n",
    "}\n",
    "with open(os.path.join(model_dir, \"lstm_model_pipeline.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(pipeline_data, file)"
   ],
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../assets/models/keras_lstm_model\\assets\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Sensitivity Analysis\n",
    "Taking the best model, we analyse here how much the amount of historical data impacts the LSTM performance. To do so we will recursively retrain (with the same hyperparameters) the LSTM based on more and more historical data. E.g., the model will first be retrained only based on 2020 data, then 2019-2020 data, etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train the model with 1 year(s) out of 7 years of data. Please wait...\n",
      "train the model with 2 year(s) out of 7 years of data. Please wait...\n",
      "train the model with 3 year(s) out of 7 years of data. Please wait...\n",
      "train the model with 4 year(s) out of 7 years of data. Please wait...\n"
     ]
    }
   ],
   "source": [
    "short_models_rmse_df = pd.DataFrame(columns=[\"nb_years\", \"rmse\"])\n",
    "for nb_years in range(1,8):\n",
    "    print(f\"train the model with {nb_years} year(s) out of 7 years of data. Please wait...\")\n",
    "    # Get the last nb_years from the training and test sets\n",
    "    X_train_short = X_train[:,-nb_years:]\n",
    "    X_test_short = X_test[:,-nb_years:]\n",
    "    # Reconfigure the model input shape with the number of years\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(m1_hyper_parameters[\"lstm_units\"], activation=m1_hyper_parameters[\"lstm_activation\"], input_shape=(nb_years, nb_features)))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    # Train the model and make predictions\n",
    "    model.compile(loss=\"mse\", optimizer=Adam(learning_rate=m1_hyper_parameters[\"learning_rate\"]), metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    model.fit(X_train_short, y_train,\n",
    "              validation_split=m1_hyper_parameters[\"validation_split\"],\n",
    "              batch_size=m1_hyper_parameters[\"batch_size\"],\n",
    "              epochs=m1_hyper_parameters[\"epochs\"],\n",
    "              shuffle=True,\n",
    "              verbose=0)\n",
    "    yhat = model.predict(X_test_short, verbose=0)\n",
    "    yhat_inverse = target_scaler.inverse_transform(yhat)\n",
    "    _, _, rmse_score = evaluate_forecast(y_test, yhat_inverse)\n",
    "    short_models_rmse_df.loc[len(short_models_rmse_df)] = [nb_years, rmse_score]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "draw_line_chart(short_models_rmse_df, x=\"nb_years\", x_title=\"Number of Years\", y=\"rmse\", y_title=\"Root Mean Square Error\", title=\"LSTM Model RMSE\", subtitle=\"Based on the number of years the model was trained on.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters Sensitivity Analysis\n",
    "We perform here an analysis of the best model's sensitivity to the following hyperparamters:\n",
    "* the optimizer used (e.g. Adam RMSprop, Adagrad)\n",
    "* the training validation datasets split\n",
    "* the number of lstm units\n",
    "* the learning rate\n",
    "* the batch size\n",
    "* the number of training epochs\n",
    "\n",
    "To perform this analysis, we trained 33,345 LSTM models for all possible combinations (within the selected ranges of values) of those 6 hyperparameters on the best model, and recorded for each model, the Root Mean Square Error (RMSE) on the test set.\n",
    "The results are stored in a CSV file available in the ../assets/tuning folder.\n",
    "\n",
    "The below visualization displays for each hyperparameter value, the distribution of the RMSE, and the mean of RMSE (using the color), for all models trained with that hyperparameter value. This allows us to show if a specific hyperparameter tends to lead to lower or higher RMSE and to compare the distribution between two values of the same hyperparameters."
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00023-e00df511-40bd-4af0-a656-131bd9752e7a",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 434.078125
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00024-6a5212a7-cc1f-47bd-aabe-ad36780f86a3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cb4f37a6",
    "execution_start": 1663514295283,
    "execution_millis": 476,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 775,
    "deepnote_output_heights": [
     606
    ],
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "hpt_df = pd.read_csv(r\"../assets/tuning/hpt_results.csv\")\n",
    "# We can discard some hyperparameter data to reduce the size of the visualization and improve readability\n",
    "#hpt_df = hpt_df[hpt_df[\"epochs\"].isin(range(50, 310, 40))]\n",
    "#hpt_df = hpt_df[hpt_df[\"lstm_units\"].isin(range(10, 200, 30))]\n",
    "draw_hyperparameters_distribution(hpt_df, [\"optimizer\", \"validation_split\", \"learning_rate\", \"batch_size\", \"epochs\", \"lstm_units\"])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at this visualization, we can see - with some surprise - that the hyperparameters which seem to have the biggest impact on the model performance have little to do with the model architecture itself (the number of LSTM units) but with how the model is trained.\n",
    "* The choice of the optimizer seems to have the largest impact on the model performance, with both the mean and distribution of the RMSE for all models trained with an `Adagrad` optimizer being really bad.\n",
    "* The training-validation percentage split seems to have little impact. The best performance is obtained with assigning 10% of the training data to the validation set, but with 15% of the training data to the validation set the results are close. We can also see that when assigning 5% of the data to the validation set, the distribution is much more even i.e., there are more models performing worse with a small validation set.\n",
    "* The bigger the learning rate, the better the model performs in terms or RMSE. The distribution of all models RMSE shows that with a learning rate of 0.01, most models have low RMSE around 40. With a learning_rate of 0.001 we have a bimodal distribution of the RMSE with models performing either around 40 or very poorly around 150. With a learning rate of 0.0001, the distribution although still bimodal is more even with most models having an RMSE above 60.\n",
    "* On the other hand, the smaller the batch size, the more models have a low RMSE.\n",
    "* Although there is less of a difference if we compare similar values (e.g., 50 and 70 epochs or 270 and 290 epochs), we still see clearly that the bigger the number training epochs the more there are trained models with a low RMSE. With a low number of epochs there are more models have an RMSE around 150.\n",
    "* The number of LSTM units, impacting the number of neurons in the LSTM model, seems to have less impact on the performance of the RMSE. The distribution of all models RMSE does show differences between 10 and 190 LSTM units but not as much as other hyperparameters. The strong bimodal distribution with a low number of LSTM units show that in this case models will either perform well or very poorly.\n",
    "\n",
    "What is also interesting is that, as seen below, if we take the combination of all the best hyperparameters\n",
    "* lstm_units: 60\n",
    "* learning_rate: 0.01\n",
    "* validation_split: 0.1\n",
    "* batch_size: 32\n",
    "* epochs: 290\n",
    "\n",
    "we end up with an MAE of 25.62 and an RMSE of 34.96 both slightly worse (respectively 23.80 and 34.77) than the best model (model 1) we found previously. The best model is thus not necessarily obtained by the combination of the best individual hyperparameters."
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00025-dea28470-c4e6-4bd4-a460-1158f23f5e87",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 784.71875
   }
  },
  {
   "cell_type": "code",
   "source": [
    "m4_hyper_parameters = {\n",
    "    \"lstm_units\": 60,\n",
    "    \"lstm_activation\": \"sigmoid\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"validation_split\": 0.1,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 290,\n",
    "}\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(m4_hyper_parameters[\"lstm_units\"], activation=m4_hyper_parameters[\"lstm_activation\"], input_shape=(7, nb_features)))\n",
    "model4.add(Dense(1, activation=\"linear\"))\n",
    "model4.summary()"
   ],
   "metadata": {
    "cell_id": "b5cfece55cc44b658337d8e08d154a7c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1183ce51",
    "execution_start": 1663514295758,
    "execution_millis": 107,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 570.4375,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model4.compile(loss=\"mse\", optimizer=Adam(learning_rate=m4_hyper_parameters[\"learning_rate\"]), metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "model4.fit(X_train, y_train,\n",
    "           validation_split=m4_hyper_parameters[\"validation_split\"],\n",
    "           batch_size=m4_hyper_parameters[\"batch_size\"],\n",
    "           epochs=m4_hyper_parameters[\"epochs\"],\n",
    "           shuffle=True)\n",
    "yhat = model4.predict(X_test, verbose=0)\n",
    "yhat_inverse = target_scaler.inverse_transform(yhat)\n",
    "model_scores_df.loc[\"hyperparameters best combination\"] = evaluate_forecast(y_test, yhat_inverse)"
   ],
   "metadata": {
    "cell_id": "1a7fa3abd6ea461bbcdadfb97a41501c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "15a64057",
    "execution_start": 1663514295872,
    "execution_millis": 56953,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 845,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model_scores_df"
   ],
   "metadata": {
    "cell_id": "a04c73538b024e10a66a9b972e9d6bca",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "693c61b9",
    "execution_start": 1663514352811,
    "execution_millis": 55,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 349,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting 2022\n",
    "Even though our best model has a too large error to be useful, we can try as an exercise, to predict the 2022 target variable for all the Township-Ranges.\n",
    "\n",
    "The model was trained to predict the 2021 data based on the previous 7 years of data 2014 to 2020. To predict 2022 we thus need to pass the previous 7 years of data (2015-2021). To do so:\n",
    "1. We use our impute pipeline trained on the training dataset to impute values on the entire dataset and normalize the data\n",
    "2. We drop the 2014 data points\n",
    "3. We reshape the dataset as a 3 dimensional numpy array in the form of [all Township-Ranges, 2015-2021, 80 features]\n",
    "\n",
    "Once we predict the 2022 values of the target variable, we extract the 2021 values from the original dataset to compare the 2021 values with the predicted 2022 values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00026-48321042-52a8-46ca-b4f3-a453861115dc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "80297276",
    "execution_start": 1663514352856,
    "execution_millis": 746,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 633.1875,
    "deepnote_output_heights": [
     410.1875
    ],
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Predict the 2022 values for all Township-Ranges for the target variable based on 2015-2021 data\n",
    "X_2015_to_2021 = get_data_for_prediction(X, impute_pipeline, impute_columns)\n",
    "yhat_2022 = model1.predict(X_2015_to_2021, verbose=0)\n",
    "yhat_inverse_2022 = target_scaler.inverse_transform(yhat_2022)\n",
    "predictions_2022_df = pd.DataFrame(yhat_inverse_2022, index=X.index.get_level_values(0).unique(), columns=[target_variable])\n",
    "# Add the 2022 values of the target variable to the existing ones\n",
    "all_years_df = combine_all_target_years(X, target_variable, predictions_2022_df)\n",
    "all_years_df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00027-9d12b0ae-369a-4731-8bef-dd99f10b9e21",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b216e253",
    "execution_start": 1663514353614,
    "execution_millis": 14517,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 739,
    "deepnote_output_heights": [
     606
    ],
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "township_range = TownshipRanges()\n",
    "all_years_map_df = pd.merge(township_range.sjv_township_range_df, all_years_df.reset_index(), how=\"left\", on=[\"TOWNSHIP_RANGE\", ])\n",
    "view_trs_side_by_side(all_years_map_df, feature=\"YEAR\", value=\"GSE_GWE\", title=\"San Joaquin Valley GSE_GWE with 2022 predictions\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "When we look at the 2022 predictions of the `GSE_GWE` compared to the actual 2014-2021 the predictions are fairly consistent. Areas with high `GSE_GWE` values (i.e., deep ground to water depth) remain the same, and area with low `GSE_GWE` remain the same. However, if the model follows the past year trend, even with a high RMSE of 34.82 feet (10.6 meters), areas with high `GSE_GWE` will remain areas of high `GSE_GWE`. Comparing the past years `GSE_GWE` measurement values with the 2022 predictions is thus only partly informative about the quality of the prediction.\n",
    "\n",
    "We thus try to also compare the year-to-year *difference* in the `GSE_GWE` from 2014 to 2021 and between our 2022 predictions and the 2021 values."
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00028-cec6234b-da6a-4d45-ae19-3a5a798568b8",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 200.734375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00029-166e1aed-dc54-46bb-a5d3-5bab6109e14d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "95f3ba13",
    "execution_start": 1663514367640,
    "execution_millis": 493,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 630,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "yty_difference_df = get_year_to_year_differences(X, target_variable, predictions_2022_df)\n",
    "yty_difference_df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00030-6cd7b0ca-adae-4912-a848-d2be91d200e2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "97bc6ad",
    "execution_start": 1663514367656,
    "execution_millis": 4753,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 721,
    "deepnote_output_heights": [
     606
    ],
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "difference_df = pd.merge(township_range.sjv_township_range_df, pd.melt(yty_difference_df.reset_index(), id_vars=[\"TOWNSHIP_RANGE\"], var_name=\"YEAR\", value_name=\"GSE_GWE_DIFFERENCE\"), how=\"left\", on=[\"TOWNSHIP_RANGE\", ])\n",
    "view_trs_side_by_side(difference_df, feature=\"YEAR\", value=\"GSE_GWE_DIFFERENCE\", title=\"San Joaquin Valley GSE_GWE year-to-year variations from 2014 until 2022 predictions\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "cell_id": "00031-0a4ec1da-d826-416e-8898-d93e09e6e55f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3e69990f",
    "execution_start": 1663514372523,
    "execution_millis": 16,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 530,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "yty_difference_df.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the above table, here too, the difference between the 2022 predictions and 2021 measurements of `GSE_GWE` remains consistent with the year-to-year difference from previous years. Despite the RMSE score being bad, the year-to-year variation of `GSE_GWE` remains within acceptable range.\n",
    "## Conclusion\n",
    "Using a simple LSTM neural network to make next year predictions based on the past 7 years of data, we are able to achieve a more accurate prediction on the test set with an RMSE of 34.77 feet (10.4 meters) compared to an RMSE between 75 and 95 feet (22.8 and 28.9 meters) using supervised algorithms like XGBoost or K-Neighbors regressor.\n",
    "\n",
    "The 2022 predictions look to be within the range of acceptable values and year-to-year variations. However, if the objective is to help policymakers and water resources management agencies predict a year in advance where to focus their attention in terms of well water shortages and drilling, the level of error of the model feels too big to be useful."
   ],
   "metadata": {
    "collapsed": false,
    "cell_id": "00032-b96cc429-58f7-40ee-a21d-ee8fc69bc8dd",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 578.515625
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2021 Predictions For Model Comparison and Failure Analysis\n",
    "The best LSTM model above was trained on a subset of Township-Ranges with all their 2014-2021 data and tested on another subset od Township-Ranges (see above \"Preparing the Dataset\" section). But other more traditional models were trained on 1 year of data to predict the next year data, with the 2021 data held as a test set.\n",
    "To compare these models side-by-side, here we discard the 2021 data, train the model on the 2014-2020 data and use the model to predict the 2021 values. The 2021 predictions are stored in a CSV file which will be used to compare with other model 2021 predictions and the real values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_shortened = X.copy()\n",
    "X_shortened.drop(\"2021\", level=1, axis=0, inplace=True)\n",
    "X_train, X_test, y_train, y_test, impute_pipeline, impute_columns, target_scaler = get_train_test_datasets(X_shortened, target_variable=target_variable, test_size=test_size, random_seed=RANDOM_SEED, save_to_file=True)\n",
    "model_predictions_df = pd.DataFrame(y_test, columns=[target_variable])\n",
    "nb_features = X_train.shape[-1]\n",
    "get_sets_shapes(X_train, X_test)\n",
    "model_predict_2021 = Sequential()\n",
    "model_predict_2021.add(LSTM(m1_hyper_parameters[\"lstm_units\"], activation=m1_hyper_parameters[\"lstm_activation\"], input_shape=(6, nb_features)))\n",
    "model_predict_2021.add(Dense(1, activation=\"linear\"))\n",
    "model_predict_2021.compile(loss=\"mse\", optimizer=Adam(learning_rate=m1_hyper_parameters[\"learning_rate\"]), metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "model_predict_2021.fit(X_train, y_train,\n",
    "           validation_split=m1_hyper_parameters[\"validation_split\"],\n",
    "           batch_size=m1_hyper_parameters[\"batch_size\"],\n",
    "           epochs=m1_hyper_parameters[\"epochs\"],\n",
    "           shuffle=True)\n",
    "# Predict the 2021 values for all Township-Ranges for the target variable based on 2015-2021 data\n",
    "X_2015_to_2020 = get_data_for_prediction(X_shortened, impute_pipeline, impute_columns)\n",
    "yhat_2021 = model_predict_2021.predict(X_2015_to_2020, verbose=0)\n",
    "yhat_inverse_2021 = target_scaler.inverse_transform(yhat_2021)\n",
    "y_2021_df = pd.DataFrame(X.xs(\"2021\", level=1, axis=0)[\"GSE_GWE\"])\n",
    "predictions_2021_df = y_2021_df.merge(pd.DataFrame(yhat_inverse_2021, index=X.index.get_level_values(0).unique(), columns=[\"LSTM\"]), how=\"left\", left_index=True, right_index=True)\n",
    "predictions_2021_df.rename(columns={\"GSE_GWE\": \"2021_GSE_GWE\"}, inplace=True)\n",
    "predictions_2021_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_dir = \"../assets/predictions/\"\n",
    "os.makedirs(os.path.dirname(predictions_dir), exist_ok=True)\n",
    "predictions_2021_df.to_csv(os.path.join(predictions_dir, \"lstm_predictions.csv\"), index=True)\n",
    "model_scores_df.rename(index={\"model 1\": \"LSTM\"}, inplace=True)\n",
    "model_scores_df.reset_index(inplace=True)\n",
    "model_scores_df.rename(columns={\"index\": \"MODEL\"},inplace=True)\n",
    "model_scores_df[model_scores_df[\"MODEL\"]==\"LSTM\"].to_csv(os.path.join(predictions_dir, \"lstm_model_errors.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 1,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "deepnote_notebook_id": "5f86a7cf-0b45-42de-a821-ea56d023ff8c",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}
